@article{akata2020research,
 author = {Akata, Zeynep and Balliet, Dan and De Rijke, Maarten and Dignum, Frank and Dignum, Virginia and Eiben, Guszti and Fokkens, Antske and Grossi, Davide and Hindriks, Koen and Hoos, Holger and others},
 doi = {10.1109/mc.2020.2996587},
 journal = {Computer},
 number = {8},
 pages = {18--28},
 publisher = {IEEE},
 title = {A research agenda for hybrid intelligence: augmenting human intellect with collaborative, adaptive, responsible, and explainable artificial intelligence},
 volume = {53},
 year = {2020}
}

@inproceedings{alivanistos2022prompting,
 author = {Dimitrios Alivanistos and Santamar{\'i}a, {Selene B{\'a}ez} and Michael Cochez and Kalo, {Jan Christoph} and {van Krieken}, Emile and Thiviyan Thanapalasingam},
 booktitle = {LM-KBC 2022 Knowledge Base Construction from Pre-trained Language Models 2022},
 doi = {10.1007/978-3-030-72308-8_8},
 editor = {Sneha Singhania and Tuan-Phong Nguyen and Simon Razniewski},
 language = {English},
 pages = {11--34},
 publisher = {CEUR-WS.org},
 series = {CEUR Workshop Proceedings},
 title = {Prompting as Probing: Using Language Models for Knowledge Base Construction},
 year = {2022}
}

@article{alkhamissi2022review,
 author = {AlKhamissi, Badr and Li, Millicent and Celikyilmaz, Asli and Diab, Mona and Ghazvininejad, Marjan},
 doi = {10.18653/v1/2022.emnlp-main.136},
 journal = {arXiv preprint arXiv:2204.06031},
 title = {A review on language models as knowledge bases},
 year = {2022}
}

@article{allen2023brief,
 author = {Allen, Bradley P},
 doi = {10.4324/9781410603098-19},
 journal = {Dagstuhl Reports},
 number = {9},
 pages = {65--72},
 publisher = {Schloss Dagstuhl - Leibniz-centrum f$\{$$\backslash$"u$\}$r Informatik},
 title = {A Brief History of Knowledge Engineering: A Practitioner’s Perspective},
 volume = {12},
 year = {2023}
}

@article{allen2023identifying,
 author = {Allen, Bradley P and Ilievski, Filip and Joshi, Saurav},
 doi = {10.18653/v1/2022.findings-emnlp.505},
 journal = {arXiv preprint arXiv:2306.15124},
 title = {Identifying and Consolidating Knowledge Engineering Requirements},
 year = {2023}
}

@inproceedings{alt2019fine,
 author = {Alt, Christoph and H{\"u}bner, Marc and Hennig, Leonhard},
 booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
 doi = {10.18653/v1/p19-1134},
 pages = {1388--1398},
 title = {Fine-tuning Pre-Trained Transformer Language Models to Distantly Supervised Relation Extraction},
 year = {2019}
}

@article{annurev-biodatasci-010820-091627,
 author = {Callahan, Tiffany J. and Tripodi, Ignacio J. and Pielke-Lombardo, Harrison and Hunter, Lawrence E.},
 doi = {10.1146/annurev-biodatasci-010820-091627},
 journal = {Annual Review of Biomedical Data Science},
 number = {1},
 pages = {23-41},
 title = {Knowledge-Based Biomedical Data Science},
 volume = {3},
 year = {2020}
}

@misc{arawjo2023chainforge,
 archiveprefix = {arXiv},
 author = {Ian Arawjo and Chelse Swoopes and Priyan Vaithilingam and Martin Wattenberg and Elena Glassman},
 doi = {10.1145/3586182.3616660},
 eprint = {2309.09128},
 primaryclass = {cs.HC},
 title = {ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing},
 year = {2023}
}

@article{austin2021program,
 author = {Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
 doi = {10.1145/3491101.3503564},
 journal = {arXiv preprint arXiv:2108.07732},
 title = {Program synthesis with large language models},
 year = {2021}
}

@article{axelsson2023using,
 author = {Axelsson, Agnes and Skantze, Gabriel},
 doi = {10.1145/3383652.3423884},
 journal = {arXiv preprint arXiv:2307.07312},
 title = {Using Large Language Models for Zero-Shot Natural Language Generation from Knowledge Graphs},
 year = {2023}
}

@inproceedings{bach-etal-2022-promptsource,
 abstract = {PromptSource is a system for creating, sharing, and using natural language prompts. Prompts are functions that map an example from a dataset to a natural language input and target output. Using prompts to train and query language models is an emerging area in NLP that requires new tools that let users develop and refine these prompts collaboratively. PromptSource addresses the emergent challenges in this new setting with (1) a templating language for defining data-linked prompts, (2) an interface that lets users quickly iterate on prompt development by observing outputs of their prompts on many examples, and (3) a community-driven set of guidelines for contributing new prompts to a common pool. Over 2,000 prompts for roughly 170 datasets are already available in PromptSource. PromptSource is available at https://github.com/bigscience-workshop/promptsource.},
 address = {Dublin, Ireland},
 author = {Bach, Stephen  and
Sanh, Victor  and
Yong, Zheng Xin  and
Webson, Albert  and
Raffel, Colin  and
Nayak, Nihal V.  and
Sharma, Abheesht  and
Kim, Taewoon  and
Bari, M Saiful  and
Fevry, Thibault  and
Alyafeai, Zaid  and
Dey, Manan  and
Santilli, Andrea  and
Sun, Zhiqing  and
Ben-david, Srulik  and
Xu, Canwen  and
Chhablani, Gunjan  and
Wang, Han  and
Fries, Jason  and
Al-shaibani, Maged  and
Sharma, Shanya  and
Thakker, Urmish  and
Almubarak, Khalid  and
Tang, Xiangru  and
Radev, Dragomir  and
Jiang, Mike Tian-jian  and
Rush, Alexander},
 booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
 doi = {10.18653/v1/2022.acl-demo.9},
 month = {May},
 pages = {93--104},
 publisher = {Association for Computational Linguistics},
 title = {{P}rompt{S}ource: An Integrated Development Environment and Repository for Natural Language Prompts},
 url = {https://aclanthology.org/2022.acl-demo.9},
 year = {2022}
}

@article{badue2021self,
 author = {Badue, Claudine and Guidolini, R{\^a}nik and Carneiro, Raphael Vivacqua and Azevedo, Pedro and Cardoso, Vinicius B and Forechi, Avelino and Jesus, Luan and Berriel, Rodrigo and Paixao, Thiago M and Mutz, Filipe and others},
 doi = {10.1016/j.eswa.2020.113816},
 journal = {Expert Systems with Applications},
 pages = {113816},
 publisher = {Elsevier},
 title = {Self-driving cars: A survey},
 volume = {165},
 year = {2021}
}

@techreport{baskauf2017tdwg,
 author = {Baskauf, Steve and Hyam, Roger and Blum, Stanley and Morris, Robert A and Rees, Jonathan and Sachs, Joel and Whitbread, Greg and Wieczorek, John},
 doi = {10.3897/biss.3.35297},
 institution = {Biodiversity Information Standards (TDWG)},
 title = {TDWG Standards Documentation Specification},
 year = {2017}
}

@inproceedings{bender2021dangers,
 author = {Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
 booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
 doi = {10.1145/3442188.3445922},
 pages = {610--623},
 title = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
 year = {2021}
}

@article{berners2001semantic,
 author = {Berners-Lee, Tim and Hendler, James and Lassila, Ora},
 doi = {10.1038/scientificamerican0501-34},
 journal = {Scientific american},
 number = {5},
 pages = {34--43},
 publisher = {JSTOR},
 title = {The semantic web},
 volume = {284},
 year = {2001}
}

@inproceedings{bezerra2013evaluating,
 author = {Bezerra, Camila and Freitas, Fred and Santana, Filipe},
 booktitle = {2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)},
 doi = {10.1109/wi-iat.2013.199},
 organization = {IEEE},
 pages = {284--285},
 title = {Evaluating ontologies with competency questions},
 volume = {3},
 year = {2013}
}

@inproceedings{bizer2008linked,
 author = {Bizer, Christian and Heath, Tom and Idehen, Kingsley and Berners-Lee, Tim},
 booktitle = {Proceedings of the 17th international conference on World Wide Web},
 doi = {10.1145/1367497.1367760},
 pages = {1265--1266},
 title = {Linked data on the web (LDOW2008)},
 year = {2008}
}

@article{blagoderov2012no,
 author = {Blagoderov, Vladimir and Kitching, Ian J and Livermore, Laurence and Simonsen, Thomas J and Smith, Vincent S},
 doi = {10.3897/zookeys.209.3178},
 journal = {ZooKeys},
 pages = {133--146},
 publisher = {Pensoft Publishers},
 title = {No specimen left behind: industrial scale digitization of natural history collections},
 volume = {209},
 year = {2012}
}

@article{bonner2022review,
 author = {Bonner, Stephen and Barrett, Ian P and Ye, Cheng and Swiers, Rowan and Engkvist, Ola and Bender, Andreas and Hoyt, Charles Tapley and Hamilton, William L},
 doi = {10.1093/bib/bbac404},
 journal = {Briefings in Bioinformatics},
 number = {6},
 pages = {bbac404},
 publisher = {Oxford University Press},
 title = {A review of biomedical datasets relating to drug discovery: a knowledge graph perspective},
 volume = {23},
 year = {2022}
}

@inproceedings{booch2021thinking,
 author = {Booch, Grady and Fabiano, Francesco and Horesh, Lior and Kate, Kiran and Lenchner, Jonathan and Linck, Nick and Loreggia, Andreas and Murgesan, Keerthiram and Mattei, Nicholas and Rossi, Francesca and others},
 booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
 doi = {10.1609/aaai.v35i17.17765},
 pages = {15042--15046},
 title = {Thinking fast and slow in AI},
 volume = {35},
 year = {2021}
}

@inproceedings{bosselut2019comet,
 abstract = {We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5{\%} (ATOMIC) and 91.7{\%} (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods.},
 address = {Florence, Italy},
 author = {Bosselut, Antoine  and
Rashkin, Hannah  and
Sap, Maarten  and
Malaviya, Chaitanya  and
Celikyilmaz, Asli  and
Choi, Yejin},
 booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
 doi = {10.18653/v1/p19-1470},
 month = {July},
 pages = {4762--4779},
 publisher = {Association for Computational Linguistics},
 title = {{COMET}: Commonsense Transformers for Automatic Knowledge Graph Construction},
 url = {https://aclanthology.org/P19-1470},
 year = {2019}
}

@article{breit2023combining,
 author = {Breit, Anna and Waltersdorfer, Laura and Ekaputra, Fajar J and Sabou, Marta and Ekelhart, Andreas and Iana, Andreea and Paulheim, Heiko and Portisch, Jan and Revenko, Artem and Teije, Annette ten and others},
 doi = {10.3233/faia230136},
 journal = {ACM Computing Surveys},
 publisher = {ACM New York, NY},
 title = {Combining machine learning and semantic web: A systematic mapping study},
 year = {2023}
}

@article{brown2020language,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
 doi = {10.1145/3531146.3533229},
 journal = {Advances in neural information processing systems},
 pages = {1877--1901},
 title = {Language models are few-shot learners},
 volume = {33},
 year = {2020}
}

@book{cappelen2021making,
 author = {Cappelen, Herman and Dever, Josh},
 doi = {10.1093/oso/9780192894724.001.0001},
 publisher = {Oxford University Press},
 title = {Making AI intelligible: Philosophical foundations},
 year = {2021}
}

@inproceedings{caron2021emerging,
 author = {Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
 booktitle = {Proceedings of the IEEE/CVF international conference on computer vision},
 doi = {10.1109/iccv48922.2021.00951},
 pages = {9650--9660},
 title = {Emerging properties in self-supervised vision transformers},
 year = {2021}
}

@book{carus2007carnap,
 author = {Carus, Andr{\'e} W},
 doi = {10.1017/cbo9780511487132},
 publisher = {Cambridge University Press},
 title = {Carnap and twentieth-century thought: Explication as enlightenment},
 year = {2007}
}

@article{chang2023survey,
 author = {Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Zhu, Kaijie and Chen, Hao and Yang, Linyi and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others},
 doi = {10.18653/v1/2023.findings-acl.806},
 journal = {arXiv preprint arXiv:2307.03109},
 title = {A Survey on Evaluation of Large Language Models},
 year = {2023}
}

@incollection{chari2020directions,
 author = {Chari, Shruthi and Gruen, Daniel M and Seneviratne, Oshani and McGuinness, Deborah L},
 booktitle = {Knowledge Graphs for eXplainable Artificial Intelligence: Foundations, Applications and Challenges},
 doi = {10.1109/icdew53142.2021.00010},
 pages = {245--261},
 publisher = {IOS Press},
 title = {Directions for Explainable Knowledge-Enabled Systems},
 year = {2020}
}

@article{cohen2023crawling,
 author = {Cohen, Roi and Geva, Mor and Berant, Jonathan and Globerson, Amir},
 doi = {10.18653/v1/2023.findings-eacl.139},
 journal = {arXiv preprint arXiv:2301.12810},
 title = {Crawling the Internal Knowledge-Base of Language Models},
 year = {2023}
}

@article{collobert2011natural,
 author = {Collobert, Ronan and Weston, Jason and Bottou, L{\'e}on and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
 doi = {10.1109/icdm.2009.40},
 journal = {Journal of machine learning research},
 number = {ARTICLE},
 pages = {2493--2537},
 title = {Natural language processing (almost) from scratch},
 volume = {12},
 year = {2011}
}

@book{crawford2021atlas,
 author = {Crawford, Kate},
 doi = {10.2307/j.ctv1ghv45t},
 publisher = {Yale University Press},
 title = {The atlas of AI: Power, politics, and the planetary costs of artificial intelligence},
 year = {2021}
}

@article{creswell2022selection,
 author = {Creswell, Antonia and Shanahan, Murray and Higgins, Irina},
 doi = {10.3390/encyclopedia3020049},
 journal = {arXiv preprint arXiv:2205.09712},
 title = {Selection-inference: Exploiting large language models for interpretable logical reasoning},
 year = {2022}
}

@article{daga2023data,
 author = {Daga, Enrico and Groth, Paul},
 doi = {10.3233/sw-233407},
 journal = {Semantic Web},
 pages = {1--27},
 publisher = {IOS Press},
 title = {Data journeys: explaining AI workflows through abstraction},
 volume = {Preprint},
 year = {2023}
}

@article{DBLP:journals/corr/abs-2202-01875,
 author = {Himabindu Lakkaraju and
Dylan Slack and
Yuxin Chen and
Chenhao Tan and
Sameer Singh},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/journals/corr/abs-2202-01875.bib},
 doi = {10.21203/rs.3.rs-2129845/v1},
 eprint = {2202.01875},
 eprinttype = {arXiv},
 journal = {CoRR},
 timestamp = {Tue, 25 Apr 2023 07:40:33 +0200},
 title = {Rethinking Explainability as a Dialogue: {A} Practitioner's Perspective},
 url = {https://arxiv.org/abs/2202.01875},
 volume = {abs/2202.01875},
 year = {2022}
}

@inproceedings{de2012nichesourcing,
 author = {De Boer, Victor and Hildebrand, Michiel and Aroyo, Lora and De Leenheer, Pieter and Dijkshoorn, Chris and Tesfa, Binyam and Schreiber, Guus},
 booktitle = {Knowledge Engineering and Knowledge Management: 18th International Conference, EKAW 2012, Galway City, Ireland, October 8-12, 2012. Proceedings 18},
 doi = {10.1007/978-3-642-33876-2_3},
 organization = {Springer},
 pages = {16--20},
 title = {Nichesourcing: harnessing the power of crowds of experts},
 year = {2012}
}

@article{devlin2018bert,
 author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
 doi = {10.18653/v1/n19-1423},
 journal = {arXiv preprint arXiv:1810.04805},
 title = {Bert: Pre-training of deep bidirectional transformers for language understanding},
 year = {2018}
}

@inproceedings{dijkshoorn2013personalized,
 author = {Dijkshoorn, Chris and Leyssen, Mieke HR and Nottamkandath, Archana and Oosterman, Jasper and Traub, Myriam C and Aroyo, Lora and Bozzon, Alessandro and Fokkink, Wan J and Houben, Geert-Jan and Hovelmann, Henrike and others},
 booktitle = {UMAP Workshops},
 doi = {10.1145/2567948.2576960},
 title = {Personalized Nichesourcing: Acquisition of Qualitative Annotations from Niche Communities.},
 year = {2013}
}

@inproceedings{dovsilovic2018explainable,
 author = {Do{\v{s}}ilovi{\'c}, Filip Karlo and Br{\v{c}}i{\'c}, Mario and Hlupi{\'c}, Nikica},
 booktitle = {2018 41st International convention on information and communication technology, electronics and microelectronics (MIPRO)},
 doi = {10.23919/mipro.2018.8400040},
 organization = {IEEE},
 pages = {0210--0215},
 title = {Explainable artificial intelligence: A survey},
 year = {2018}
}

@article{dutilh2017carnapian,
 author = {Dutilh Novaes, Catarina and Reck, Erich},
 doi = {10.1007/s11229-015-0816-z},
 journal = {Synthese},
 pages = {195--215},
 publisher = {Springer},
 title = {Carnapian explication, formalisms as cognitive tools, and the paradox of adequate formalization},
 volume = {194},
 year = {2017}
}

@inproceedings{ekaputra2023describing,
 author = {Ekaputra, Fajar J and Llugiqi, Majlinda and Sabou, Marta and Ekelhart, Andreas and Paulheim, Heiko and Breit, Anna and Revenko, Artem and Waltersdorfer, Laura and Farfar, Kheir Eddine and Auer, S{\"o}ren},
 booktitle = {European Semantic Web Conference},
 doi = {10.1007/978-3-031-33455-9_22},
 organization = {Springer},
 pages = {372--389},
 title = {Describing and Organizing Semantic Web and Machine Learning Systems in the SWeMLS-KG},
 year = {2023}
}

@inproceedings{feigenbaum1977art,
 author = {Feigenbaum, Edward A},
 booktitle = {Proceedings of the Fifth International Joint Conference on Artificial Intelligence},
 doi = {10.21236/ada046289},
 organization = {Boston},
 title = {The art of artificial intelligence: Themes and case studies of knowledge engineering},
 volume = {2},
 year = {1977}
}

@article{FEIGENBAUM1984,
 author = {EDWARD A. FEIGENBAUM},
 doi = {10.21236/ada046289},
 journal = {Annals of the New York Academy of Sciences},
 month = {November},
 number = {1 Computer Cult},
 pages = {91--107},
 publisher = {Wiley},
 title = {Knowledge Engineering.},
 url = {https://doi.org/10.1111/j.1749-6632.1984.tb16513.x},
 volume = {426},
 year = {1984}
}

@book{feigenbaum1992personal,
 author = {Feigenbaum, Edward A},
 doi = {10.1016/0957-4174(92)90004-c},
 publisher = {Knowledge Systems Laboratory, Department of Computer Science, Stanford~…},
 title = {A personal view of expert systems: Looking back and looking ahead},
 year = {1992}
}

@article{foundationmodel2021,
 author = {Rishi Bommasani and et al.},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/journals/corr/abs-2108-07258.bib},
 doi = {10.1145/3544549.3583177},
 eprint = {2108.07258},
 eprinttype = {arXiv},
 journal = {CoRR},
 timestamp = {Fri, 17 Feb 2023 09:02:02 +0100},
 title = {On the Opportunities and Risks of Foundation Models},
 url = {https://arxiv.org/abs/2108.07258},
 volume = {abs/2108.07258},
 year = {2021}
}

@book{gabbay2004rise,
 author = {Gabbay, Dov M and Woods, John},
 doi = {10.1016/s1874-5857(04)80012-8},
 publisher = {Elsevier},
 title = {The rise of modern logic: from Leibniz to Frege},
 year = {2004}
}

@incollection{gangemi2009ontology,
 author = {Gangemi, Aldo and Presutti, Valentina},
 booktitle = {Handbook on ontologies},
 doi = {10.1007/978-3-540-92673-3_10},
 pages = {221--243},
 publisher = {Springer},
 title = {Ontology design patterns},
 year = {2009}
}

@article{gehrmann2021gem,
 author = {Gehrmann, Sebastian and Adewumi, Tosin and Aggarwal, Karmanya and Ammanamanchi, Pawan Sasanka and Anuoluwapo, Aremu and Bosselut, Antoine and Chandu, Khyathi Raghavi and Clinciu, Miruna and Das, Dipanjan and Dhole, Kaustubh D and others},
 doi = {10.18653/v1/2021.gem-1.10},
 journal = {arXiv preprint arXiv:2102.01672},
 title = {The gem benchmark: Natural language generation, its evaluation and metrics},
 year = {2021}
}

@article{glymour1998ramon,
 author = {Glymour, Clark and Ford, Kenneth M and Hayes, Patrick J},
 doi = {10.1609/aimag.v36i4.2629},
 journal = {AI Magazine},
 number = {2},
 pages = {136--136},
 title = {Ram{\'o}n Lull and the infidels},
 volume = {19},
 year = {1998}
}

@article{godfray2002challenges,
 author = {Godfray, H Charles J},
 doi = {10.1038/417017a},
 journal = {Nature},
 number = {6884},
 pages = {17--19},
 publisher = {Nature Publishing Group UK London},
 title = {Challenges for taxonomy},
 volume = {417},
 year = {2002}
}

@article{goodfellow2020generative,
 author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
 doi = {10.1145/3422622},
 journal = {Communications of the ACM},
 number = {11},
 pages = {139--144},
 publisher = {ACM New York, NY, USA},
 title = {Generative adversarial networks},
 volume = {63},
 year = {2020}
}

@article{groth2023forms,
 author = { Groth, Paul and Hogan, Aidan and Stork, Lise and Thornton, Katherine and Vrandečić Denny},
 doi = {10.1007/978-3-540-88845-1_13},
 journal = {Dagstuhl Reports},
 number = {9},
 pages = {101--105},
 publisher = {Schloss Dagstuhl - Leibniz-centrum f$\{$$\backslash$"u$\}$r Informatik},
 title = {Knowledge Graphs vs. Other Forms of Knowledge Representation},
 volume = {12},
 year = {2023}
}

@inproceedings{groth2023knowledge,
 author = {Groth, Paul and Simperl, Elena and van Erp, Marieke and Vrande{\v{c}}i{\'c}, Denny},
 booktitle = {Dagstuhl Reports},
 doi = {10.1007/978-3-642-19510-5_3},
 number = {9},
 organization = {Schloss Dagstuhl-Leibniz-Zentrum f{\"u}r Informatik},
 title = {Knowledge Graphs and their Role in the Knowledge Engineering of the 21st Century (Dagstuhl Seminar 22372)},
 volume = {12},
 year = {2023}
}

@article{guo2020cyclegt,
 author = {Guo, Qipeng and Jin, Zhijing and Qiu, Xipeng and Zhang, Weinan and Wipf, David and Zhang, Zheng},
 doi = {10.18653/v1/2020.coling-main.217},
 journal = {arXiv preprint arXiv:2006.04702},
 title = {Cyclegt: Unsupervised graph-to-text and text-to-graph generation via cycle training},
 year = {2020}
}

@article{gurrapu2023rationalization,
 author = {Gurrapu, Sai and Kulkarni, Ajay and Huang, Lifu and Lourentzou, Ismini and Freeman, Laura and Batarseh, Feras A},
 doi = {10.3389/frai.2023.1225093},
 journal = {arXiv preprint arXiv:2301.08912},
 title = {Rationalization for explainable nlp: A survey},
 year = {2023}
}

@article{gwinn2009biodiversity,
 author = {Gwinn, Nancy E and Rinaldo, Constance},
 doi = {10.1177/0340035208102032},
 journal = {IFLA journal},
 number = {1},
 pages = {25--34},
 publisher = {Sage Publications Sage UK: London, England},
 title = {The Biodiversity Heritage Library: sharing biodiversity literature with the world},
 volume = {35},
 year = {2009}
}

@article{hardisty2022digital,
 author = {Hardisty, Alex R and Ellwood, Elizabeth R and Nelson, Gil and Zimkus, Breda and Buschbom, Jutta and Addink, Wouter and Rabeler, Richard K and Bates, John and Bentley, Andrew and Fortes, Jos{\'e} AB and others},
 doi = {10.1093/biosci/biac060},
 journal = {BioScience},
 number = {10},
 pages = {978--987},
 publisher = {Oxford University Press},
 title = {Digital extended specimens: Enabling an extensible network of biodiversity data records as integrated digital objects on the internet},
 volume = {72},
 year = {2022}
}

@book{hayes1983building,
 author = {Hayes-Roth, Frederick and Waterman, Donald A and Lenat, Douglas B},
 doi = {10.1017/s0263574700004069},
 publisher = {Addison-Wesley Longman Publishing Co., Inc.},
 title = {Building expert systems},
 year = {1983}
}

@article{hedrick2020digitization,
 author = {Hedrick, Brandon P and Heberling, J Mason and Meineke, Emily K and Turner, Kathryn G and Grassa, Christopher J and Park, Daniel S and Kennedy, Jonathan and Clarke, Julia A and Cook, Joseph A and Blackburn, David C and others},
 doi = {10.7287/peerj.preprints.27859v1},
 journal = {BioScience},
 number = {3},
 pages = {243--251},
 publisher = {Oxford University Press},
 title = {Digitization and the future of natural history collections},
 volume = {70},
 year = {2020}
}

@book{hendler2020semantic,
 author = {Hendler, James and Gandon, Fabien and Allemang, Dean},
 doi = {10.1145/3382097},
 publisher = {Morgan \& Claypool},
 title = {Semantic web for the working ontologist: Effective modeling for linked data, RDFS, and OWL},
 year = {2020}
}

@article{hjorland2008knowledge,
 author = {Hj{\o}rland, Birger},
 doi = {10.5771/0943-7444-2008-2-3-86},
 journal = {KO Knowledge Organization},
 number = {2-3},
 pages = {86--101},
 publisher = {Nomos Verlagsgesellschaft mbH \& Co. KG},
 title = {What is knowledge organization (KO)?},
 volume = {35},
 year = {2008}
}

@article{hogan2021knowledge,
 author = {Hogan, Aidan and Blomqvist, Eva and Cochez, Michael and d’Amato, Claudia and Melo, Gerard de and Gutierrez, Claudio and Kirrane, Sabrina and Gayo, Jos{\'e} Emilio Labra and Navigli, Roberto and Neumaier, Sebastian and others},
 doi = {10.1007/978-3-031-01918-0},
 journal = {ACM Computing Surveys (CSUR)},
 number = {4},
 pages = {1--37},
 publisher = {ACM New York, NY, USA},
 title = {Knowledge graphs},
 volume = {54},
 year = {2021}
}

@inproceedings{hulsebos2019sherlock,
 author = {Hulsebos, Madelon and Hu, Kevin and Bakker, Michiel and Zgraggen, Emanuel and Satyanarayan, Arvind and Kraska, Tim and Demiralp, {\c{C}}agatay and Hidalgo, C{\'e}sar},
 booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
 doi = {10.1145/3292500.3330993},
 pages = {1500--1508},
 title = {Sherlock: A deep learning approach to semantic data type detection},
 year = {2019}
}

@inproceedings{jain2022jigsaw,
 author = {Jain, Naman and Vaidyanath, Skanda and Iyer, Arun and Natarajan, Nagarajan and Parthasarathy, Suresh and Rajamani, Sriram and Sharma, Rahul},
 booktitle = {Proceedings of the 44th International Conference on Software Engineering},
 doi = {10.1145/3510003.3510203},
 pages = {1219--1231},
 title = {Jigsaw: Large language models meet program synthesis},
 year = {2022}
}

@article{ji2023survey,
 author = {Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
 doi = {10.1145/3571730},
 journal = {ACM Computing Surveys},
 number = {12},
 pages = {1--38},
 publisher = {ACM New York, NY},
 title = {Survey of hallucination in natural language generation},
 volume = {55},
 year = {2023}
}

@book{kahneman2011thinking,
 author = {Kahneman, Daniel},
 doi = {10.1007/978-3-476-05728-0_23619-1},
 publisher = {macmillan},
 title = {Thinking, fast and slow},
 year = {2011}
}

@article{kapli2020phylogenetic,
 author = {Kapli, Paschalia and Yang, Ziheng and Telford, Maximilian J},
 doi = {10.1038/s41576-020-0233-0},
 journal = {Nature Reviews Genetics},
 number = {7},
 pages = {428--444},
 publisher = {Nature Publishing Group UK London},
 title = {Phylogenetic tree building in the genomic age},
 volume = {21},
 year = {2020}
}

@book{kendall2019ontology,
 author = {Kendall, Elisa F and McGuinness, Deborah L},
 doi = {10.1007/978-3-031-79486-5},
 publisher = {Morgan \& Claypool Publishers},
 title = {Ontology engineering},
 year = {2019}
}

@inproceedings{keywords2023,
 abstract = {It is essential to understand research trends for researchers, decision-makers, and investors. One way to analyze research trends is to collect and analyze author-defined keywords in scientific papers. Unfortunately, while author-defined keywords are beneficial to researchers aiming to figure out the trends of their research fields, 45\% of scientific papers in Microsoft Academic Graph did not contain their author-defined keywords. Additionally, six of the top seven AI conferences neither collect nor disclose keywords. This paper proposes a method for generating the keywords using Galactica, a pre-trained large language model published by Meta. We evaluate this method’s performance by comparing the keywords provided by authors in the CoRL’22 and report characteristics of the generated keywords. Our study shows the F1 score of our proposed method was ten times better than that of previous studies, and 42.7\% of the generated keywords are relevant to author-defined keywords.},
 address = {New York, NY, USA},
 author = {Lee, Wanhae and Chun, Minki and Jeong, Hyeonhak and Jung, Hyunggu},
 booktitle = {Companion Proceedings of the 28th International Conference on Intelligent User Interfaces},
 doi = {10.1145/3581754.3584126},
 isbn = {9798400701078},
 keywords = {text mining, language model, text generation, keywords},
 location = {Sydney, NSW, Australia},
 numpages = {4},
 pages = {37–40},
 publisher = {Association for Computing Machinery},
 series = {IUI '23 Companion},
 title = {Toward Keyword Generation through Large Language Models},
 url = {https://doi.org/10.1145/3581754.3584126},
 year = {2023}
}

@inproceedings{kgpromptfusion2023,
 abstract = {Knowledge graphs (KG) are essential background knowledge providers in many tasks. When designing models for KG-related tasks, one of the key tasks is to devise the Knowledge Representation and Fusion (KRF) module that learns the representation of elements from KGs and fuses them with task representations. While due to the difference of KGs and perspectives to be considered during fusion across tasks, duplicate and ad hoc KRF modules design are conducted among tasks. In this paper, we propose a novel knowledge graph pretraining model KGTransformer that could serve as a uniform KRF module in diverse KG-related tasks. We pretrain KGTransformer with three self-supervised tasks with sampled sub-graphs as input. For utilization, we propose a general prompt-tuning mechanism regarding task data as a triple prompt to allow flexible interactions between task KGs and task data. We evaluate pretrained KGTransformer on three tasks, triple classification, zero-shot image classification, and question answering. KGTransformer consistently achieves better results than specifically designed task models. Through experiments, we justify that the pretrained KGTransformer could be used off the shelf as a general and effective KRF module across KG-related tasks. The code and datasets are available at https://github.com/zjukg/KGTransformer.},
 address = {New York, NY, USA},
 author = {Zhang, Wen and Zhu, Yushan and Chen, Mingyang and Geng, Yuxia and Huang, Yufeng and Xu, Yajing and Song, Wenting and Chen, Huajun},
 booktitle = {Proceedings of the ACM Web Conference 2023},
 doi = {10.1145/3543507.3583301},
 isbn = {9781450394161},
 keywords = {pretrain and fine-tune, knowledge transfer, knowledge graph},
 location = {Austin, TX, USA},
 numpages = {10},
 pages = {2581–2590},
 publisher = {Association for Computing Machinery},
 series = {WWW '23},
 title = {Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer},
 url = {https://doi.org/10.1145/3543507.3583301},
 year = {2023}
}

@article{kojima2022large,
 author = {Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
 doi = {10.1527/tjsai.38-6_b-mc2},
 journal = {Advances in neural information processing systems},
 pages = {22199--22213},
 title = {Large language models are zero-shot reasoners},
 volume = {35},
 year = {2022}
}

@article{korini2023column,
 author = {Korini, Keti and Bizer, Christian},
 doi = {10.1007/978-3-540-92913-0_6},
 journal = {arXiv preprint arXiv:2306.00745},
 title = {Column Type Annotation using ChatGPT},
 year = {2023}
}

@article{kung2023performance,
 author = {Kung, Tiffany H and Cheatham, Morgan and Medenilla, Arielle and Sillos, Czarina and De Leon, Lorie and Elepa{\~n}o, Camille and Madriaga, Maria and Aggabao, Rimel and Diaz-Candido, Giezel and Maningo, James and others},
 doi = {10.1101/2022.12.19.22283643},
 journal = {PLoS digital health},
 number = {2},
 pages = {e0000198},
 publisher = {Public Library of Science},
 title = {Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models},
 volume = {2},
 year = {2023}
}

@inproceedings{leake2021supporting,
 author = {Leake, David and Ye, Xiaomeng and Crandall, David},
 booktitle = {AAAI Spring Symposium: Combining Machine Learning with Knowledge Engineering},
 doi = {10.1007/978-3-031-14923-8_10},
 title = {Supporting Case-Based Reasoning with Neural Networks: An Illustration for Case Adaptation},
 volume = {2},
 year = {2021}
}

@article{liu2023pre,
 author = {Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
 doi = {10.1145/3560815},
 journal = {ACM Computing Surveys},
 number = {9},
 pages = {1--35},
 publisher = {ACM New York, NY},
 title = {Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
 volume = {55},
 year = {2023}
}

@article{lorandi2023data,
 author = {Lorandi, Michela and Belz, Anya},
 doi = {10.18653/v1/2023.wassa-1.30},
 journal = {arXiv preprint arXiv:2308.09957},
 title = {Data-to-text Generation for Severely Under-Resourced Languages with GPT-3.5: A Bit of Help Needed from Google Translate},
 year = {2023}
}

@book{macgregor2018naturalists,
 author = {MacGregor, Arthur},
 doi = {10.1163/9789004323841},
 publisher = {Brill},
 title = {Naturalists in the field: collecting, recording and preserving the natural world from the fifteenth to the twenty-first century},
 volume = {2},
 year = {2018}
}

@article{madaan2023self,
 author = {Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
 doi = {10.18653/v1/2022.csrr-1.7},
 journal = {arXiv preprint arXiv:2303.17651},
 title = {Self-refine: Iterative refinement with self-feedback},
 year = {2023}
}

@article{mahowald2023dissociating,
 author = {Mahowald, Kyle and Ivanova, Anna A and Blank, Idan A and Kanwisher, Nancy and Tenenbaum, Joshua B and Fedorenko, Evelina},
 doi = {10.1101/2020.06.26.174482},
 journal = {arXiv preprint arXiv:2301.06627},
 title = {Dissociating language and thought in large language models: a cognitive perspective},
 year = {2023}
}

@article{MartinezRodriguez2020,
 author = {Jose L. Martinez-Rodriguez and Aidan Hogan and Ivan Lopez-Arevalo},
 doi = {10.3233/sw-180333},
 editor = {Andreas Hotho},
 journal = {Semantic Web},
 month = {February},
 number = {2},
 pages = {255--335},
 publisher = {{IOS} Press},
 title = {Information extraction meets the Semantic Web: A survey},
 url = {https://doi.org/10.3233/sw-180333},
 volume = {11},
 year = {2020}
}

@article{menary2007writing,
 author = {Menary, Richard},
 doi = {10.1016/j.langsci.2007.01.005},
 journal = {Language sciences},
 number = {5},
 pages = {621--632},
 publisher = {Elsevier},
 title = {Writing as thinking},
 volume = {29},
 year = {2007}
}

@article{menary2010dimensions,
 author = {Menary, Richard},
 doi = {10.1007/s11097-010-9186-7},
 journal = {Phenomenology and the Cognitive Sciences},
 pages = {561--578},
 publisher = {Springer},
 title = {Dimensions of mind},
 volume = {9},
 year = {2010}
}

@book{mercier2017enigma,
 author = {Mercier, Hugo and Sperber, Dan},
 doi = {10.2307/j.ctv2sp3dd8},
 publisher = {Harvard University Press},
 title = {The enigma of reason},
 year = {2017}
}

@article{mialon2023augmented,
 author = {Mialon, Gr{\'e}goire and Dess{\`\i}, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raileanu, Roberta and Rozi{\`e}re, Baptiste and Schick, Timo and Dwivedi-Yu, Jane and Celikyilmaz, Asli and others},
 doi = {10.21203/rs.3.rs-2116541/v1},
 journal = {arXiv preprint arXiv:2302.07842},
 title = {Augmented language models: a survey},
 year = {2023}
}

@article{mikolov2013distributed,
 author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
 doi = {10.3115/v1/w15-1502},
 journal = {Advances in neural information processing systems},
 title = {Distributed representations of words and phrases and their compositionality},
 volume = {26},
 year = {2013}
}

@article{miracle2020natuurkundige,
 author = {Miracle, Eul{\`a}lia Gass{\'o} and Stork, Lise and Weber, Andreas and Ameryan, Mahya and Wolstencroft, Katherine},
 doi = {10.1007/978-3-319-75826-8_13},
 title = {Natuurkundige Commissie Archives Online (Visual edition)},
 year = {2020}
}

@article{muller2017names,
 author = {M{\"u}ller-Wille, Staffan},
 doi = {10.1086/693560},
 journal = {Osiris},
 number = {1},
 pages = {109--128},
 publisher = {University of Chicago Press Chicago, IL},
 title = {Names and Numbers:``Data'' in Classical Natural History, 1758--1859},
 volume = {32},
 year = {2017}
}

@article{nasar2021named,
 author = {Nasar, Zara and Jaffry, Syed Waqar and Malik, Muhammad Kamran},
 doi = {10.1145/3445965},
 journal = {ACM Computing Surveys (CSUR)},
 number = {1},
 pages = {1--39},
 publisher = {ACM New York, NY, USA},
 title = {Named entity recognition and relation extraction: State-of-the-art},
 volume = {54},
 year = {2021}
}

@phdthesis{neon2010,
 added-at = {2011-06-10T09:04:03.000+0200},
 address = {Madrid, Spain},
 author = {del Carmen Su\'{a}rez de Figueroa Baonza, Mar\'{i}a},
 biburl = {https://www.bibsonomy.org/bibtex/2688a2eb655c9df88f801cb3b4821809e/bluedolphin},
 doi = {10.20868/upm.thesis.3879},
 interhash = {073c26cc3b5cb9971202803e0d47186e},
 intrahash = {688a2eb655c9df88f801cb3b4821809e},
 keywords = {imported},
 month = {June},
 owner = {braun},
 school = {Universidad Polit\'{e}cnica de Madrid},
 timestamp = {2011-06-10T09:04:13.000+0200},
 title = {NeOn Methodology for Building Ontology Networks: Specification, Scheduling
and Reuse},
 url = {http://oa.upm.es/3879/2/MARIA_DEL-_CARMEN_SUAREZ_DE_FIGUEROA_BAONZA.pdf},
 year = {2010}
}

@article{newell1982knowledge,
 author = {Newell, Allen},
 doi = {10.21236/ada106556},
 journal = {Artificial intelligence},
 number = {1},
 pages = {87--127},
 publisher = {Elsevier},
 title = {The knowledge level},
 volume = {18},
 year = {1982}
}

@article{nlpPLMSurvey2023,
 abstract = {Large, pre-trained language models (PLMs) such as BERT and GPT have drastically changed the Natural Language Processing (NLP) field. For numerous NLP tasks, approaches leveraging PLMs have achieved state-of-the-art performance. The key idea is to learn a generic, latent representation of language from a generic task once, then share it across disparate NLP tasks. Language modeling serves as the generic task, one with abundant self-supervised text available for extensive training. This article presents the key fundamental concepts of PLM architectures and a comprehensive view of the shift to PLM-driven NLP techniques. It surveys work applying the pre-training then fine-tuning, prompting, and text generation approaches. In addition, it discusses PLM limitations and suggested directions for future research.},
 address = {New York, NY, USA},
 author = {Min, Bonan and Ross, Hayley and Sulem, Elior and Veyseh, Amir Pouran Ben and Nguyen, Thien Huu and Sainz, Oscar and Agirre, Eneko and Heintz, Ilana and Roth, Dan},
 doi = {10.1145/3605943},
 issn = {0360-0300},
 journal = {ACM Comput. Surv.},
 month = {jun},
 note = {Just Accepted},
 publisher = {Association for Computing Machinery},
 title = {Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey},
 url = {https://doi.org/10.1145/3605943},
 year = {2023}
}

@book{novaes2012formal,
 author = {Novaes, Catarina Dutilh},
 doi = {10.1017/cbo9781139108010},
 publisher = {Cambridge University Press},
 title = {Formal languages in logic: A philosophical and cognitive analysis},
 year = {2012}
}

@book{novaes2020dialogical,
 author = {Novaes, Catarina Dutilh},
 doi = {10.1017/9781108800792},
 publisher = {Cambridge University Press},
 title = {The dialogical roots of deduction: Historical, cognitive, and philosophical perspectives on reasoning},
 year = {2020}
}

@inproceedings{oosterman2014crowdsourcing,
 author = {Oosterman, Jasper and Nottamkandath, Archana and Dijkshoorn, Chris and Bozzon, Alessandro and Houben, Geert-Jan and Aroyo, Lora},
 booktitle = {Proceedings of the 2014 ACM conference on Web science},
 doi = {10.1145/2615569.2615644},
 pages = {267--268},
 title = {Crowdsourcing knowledge-intensive tasks in cultural heritage},
 year = {2014}
}

@article{ortolja2022encoding,
 author = {Ortolja-Baird, Alexandra and Nyhan, Julianne},
 doi = {10.1093/llc/fqab065},
 journal = {Digital Scholarship in the Humanities},
 number = {3},
 pages = {844--867},
 publisher = {Oxford University Press},
 title = {Encoding the haunting of an object catalogue: on the potential of digital technologies to perpetuate or subvert the silence and bias of the early-modern archive},
 volume = {37},
 year = {2022}
}

@article{page2008biodiversity,
 author = {Page, Roderic DM},
 doi = {10.59350/x3wmw-nws84},
 journal = {Briefings in bioinformatics},
 number = {5},
 pages = {345--354},
 publisher = {Oxford University Press},
 title = {Biodiversity informatics: the challenge of linking data and the role of shared identifiers},
 volume = {9},
 year = {2008}
}

@article{pan2023unifying,
 author = {Pan, Shirui and Luo, Linhao and Wang, Yufei and Chen, Chen and Wang, Jiapu and Wu, Xindong},
 doi = {10.1016/j.patcog.2021.108368},
 journal = {arXiv preprint arXiv:2306.08302},
 title = {Unifying Large Language Models and Knowledge Graphs: A Roadmap},
 year = {2023}
}

@article{park2023generative,
 author = {Park, Joon Sung and O'Brien, Joseph C and Cai, Carrie J and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
 doi = {10.1145/3586183.3606763},
 journal = {arXiv preprint arXiv:2304.03442},
 title = {Generative agents: Interactive simulacra of human behavior},
 year = {2023}
}

@article{petroni2019language,
 author = {Petroni, Fabio and Rockt{\"a}schel, Tim and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander H and Riedel, Sebastian},
 doi = {10.18653/v1/d19-1250},
 journal = {arXiv preprint arXiv:1909.01066},
 title = {Language models as knowledge bases?},
 year = {2019}
}

@inproceedings{presutti2009extreme,
 author = {Presutti, Valentina and Daga, Enrico and Gangemi, Aldo and Blomqvist, Eva},
 booktitle = {Proc. Workshop on Ontology Patterns},
 doi = {10.1007/978-3-642-24794-1_3},
 pages = {83--97},
 title = {eXtreme design with content ontology design patterns},
 year = {2009}
}

@article{pretrainpromptpredict2023,
 abstract = {This article surveys and organizes research works in a new paradigm in natural language processing, which we dub “prompt-based learning.” Unlike traditional supervised learning, which trains a model to take in an input x and predict an output y as P(y|x), prompt-based learning is based on language models that model the probability of text directly. To use these models to perform prediction tasks, the original input x is modified using a template into a textual string prompt x′ that has some unfilled slots, and then the language model is used to probabilistically fill the unfilled information to obtain a final string x̂, from which the final output y can be derived. This framework is powerful and attractive for a number of reasons: It allows the language model to be pre-trained on massive amounts of raw text, and by defining a new prompting function the model is able to perform few-shot or even zero-shot learning, adapting to new scenarios with few or no labeled data. In this article, we introduce the basics of this promising paradigm, describe a unified set of mathematical notations that can cover a wide variety of existing work, and organize existing work along several dimensions, e.g.,&nbsp;the choice of pre-trained language models, prompts, and tuning strategies. To make the field more accessible to interested beginners, we not only make a systematic review of existing works and a highly structured typology of prompt-based concepts but also release other resources, e.g., a website including constantly updated survey and paperlist.},
 address = {New York, NY, USA},
 articleno = {195},
 author = {Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
 doi = {10.1145/3560815},
 issn = {0360-0300},
 issue_date = {September 2023},
 journal = {ACM Comput. Surv.},
 keywords = {prompting, Pre-trained language models},
 month = {jan},
 number = {9},
 numpages = {35},
 publisher = {Association for Computing Machinery},
 title = {Pre-Train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing},
 url = {https://doi.org/10.1145/3560815},
 volume = {55},
 year = {2023}
}

@inproceedings{radford2021learning,
 author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
 booktitle = {International conference on machine learning},
 doi = {10.1109/cvpr52688.2022.00101},
 organization = {PMLR},
 pages = {8748--8763},
 title = {Learning transferable visual models from natural language supervision},
 year = {2021}
}

@inproceedings{radford2023robust,
 author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
 booktitle = {International Conference on Machine Learning},
 doi = {10.1109/ictc49870.2020.9289445},
 organization = {PMLR},
 pages = {28492--28518},
 title = {Robust speech recognition via large-scale weak supervision},
 year = {2023}
}

@article{ramesh2022hierarchical,
 author = {Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
 doi = {10.1109/icraie51050.2020.9358343},
 journal = {arXiv preprint arXiv:2204.06125},
 number = {2},
 pages = {3},
 title = {Hierarchical text-conditional image generation with clip latents},
 volume = {1},
 year = {2022}
}

@article{razniewski2021language,
 author = {Razniewski, Simon and Yates, Andrew and Kassner, Nora and Weikum, Gerhard},
 doi = {10.2139/ssrn.3769926},
 journal = {arXiv preprint arXiv:2110.04888},
 title = {Language models as or for knowledge bases},
 year = {2021}
}

@inproceedings{reynolds2021prompt,
 author = {Reynolds, Laria and McDonell, Kyle},
 booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
 doi = {10.1145/3411763.3451760},
 pages = {1--7},
 title = {Prompt programming for large language models: Beyond the few-shot paradigm},
 year = {2021}
}

@article{robertson2014gbif,
 author = {Robertson, Tim and D{\"o}ring, Markus and Guralnick, Robert and Bloom, David and Wieczorek, John and Braak, Kyle and Otegui, Javier and Russell, Laura and Desmet, Peter},
 doi = {10.1371/journal.pone.0102623},
 journal = {PloS one},
 number = {8},
 pages = {e102623},
 publisher = {Public Library of Science San Francisco, USA},
 title = {The GBIF integrated publishing toolkit: facilitating the efficient publishing of biodiversity data on the internet},
 volume = {9},
 year = {2014}
}

@article{rodriguez2020lynx,
 author = {Rodr{\'\i}guez-Doncel, V{\'\i}ctor and Montiel-Ponsoda, Elena},
 doi = {10.26826/law-in-context.v37i1.129},
 journal = {Law Context: A Socio-Legal J.},
 pages = {175},
 publisher = {HeinOnline},
 title = {Lynx: Towards a legal knowledge graph for multilingual europe},
 volume = {37},
 year = {2020}
}

@inproceedings{rombach2022high,
 author = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
 booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
 doi = {10.1109/cvpr52688.2022.01042},
 pages = {10684--10695},
 title = {High-resolution image synthesis with latent diffusion models},
 year = {2022}
}

@article{sarker2021deep,
 author = {Sarker, Iqbal H},
 doi = {10.20944/preprints202108.0060.v1},
 journal = {SN Computer Science},
 number = {6},
 pages = {420},
 publisher = {Springer},
 title = {Deep learning: a comprehensive overview on techniques, taxonomy, applications and research directions},
 volume = {2},
 year = {2021}
}

@article{saunders2022self,
 author = {Saunders, William and Yeh, Catherine and Wu, Jeff and Bills, Steven and Ouyang, Long and Ward, Jonathan and Leike, Jan},
 doi = {10.21437/interspeech.2020-2079},
 journal = {arXiv preprint arXiv:2206.05802},
 title = {Self-critiquing models for assisting human evaluators},
 year = {2022}
}

@misc{schick2023toolformer,
 archiveprefix = {arXiv},
 author = {Timo Schick and Jane Dwivedi-Yu and Roberto Dessì and Roberta Raileanu and Maria Lomeli and Luke Zettlemoyer and Nicola Cancedda and Thomas Scialom},
 doi = {10.21203/rs.3.rs-2116541/v1},
 eprint = {2302.04761},
 primaryclass = {cs.CL},
 title = {Toolformer: Language Models Can Teach Themselves to Use Tools},
 year = {2023}
}

@book{schreiber2000knowledge,
 author = {Schreiber, Guus and Akkermans, Hans and Anjewierden, Anjo and Shadbolt, Nigel and de Hoog, Robert and Van de Velde, Walter and Wielinga, Bob},
 doi = {10.7551/mitpress/4073.001.0001},
 publisher = {MIT press},
 title = {Knowledge engineering and management: the CommonKADS methodology},
 year = {2000}
}

@article{schreiber2008knowledge,
 author = {Schreiber, Guus},
 doi = {10.1016/s1574-6526(07)03025-8},
 journal = {Foundations of Artificial Intelligence},
 pages = {929--946},
 publisher = {Elsevier},
 title = {Knowledge engineering},
 volume = {3},
 year = {2008}
}

@inproceedings{schreiber2008principles,
 author = {Schreiber, Guus and Aroyo, Lora},
 booktitle = {AAAI Spring Symposium: Symbiotic Relationships between Semantic Web and Knowledge Engineering},
 doi = {10.1109/mis.2009.32},
 pages = {78--82},
 title = {Principles for Knowledge Engineering on the Web.},
 year = {2008}
}

@article{shadbolt2015knowledge,
 author = {Shadbolt, Nigel R and Smart, Paul R and Wilson, J and Sharples, S},
 doi = {10.1109/kimas.2007.369841},
 journal = {Evaluation of human work},
 pages = {163--200},
 publisher = {CRC Press},
 title = {Knowledge elicitation},
 year = {2015}
}

@article{shanahan2022talking,
 author = {Shanahan, Murray},
 doi = {10.1038/s41586-023-06647-8},
 journal = {arXiv preprint arXiv:2212.03551},
 title = {Talking About Large Language Models},
 year = {2022}
}

@article{simperl2023knowledge,
 author = {Simperl, Elena and Groth, Paul and Staab, Steffen and Sabou, Marta and Blomqvist, Eva and Allen, Bradley},
 doi = {10.1007/978-3-319-46523-4},
 journal = {Dagstuhl Reports},
 number = {9},
 pages = {93--96},
 publisher = {Schloss Dagstuhl - Leibniz-centrum f$\{$$\backslash$"u$\}$r Informatik},
 title = {Knowledge Engineering with Language Models and Neural Methods},
 volume = {12},
 year = {2023}
}

@misc{sourati2023casebased,
 archiveprefix = {arXiv},
 author = {Zhivar Sourati and Filip Ilievski and Hông-Ân Sandlin and Alain Mermoud},
 doi = {10.24963/ijcai.2023/576},
 eprint = {2301.11879},
 primaryclass = {cs.AI},
 title = {Case-Based Reasoning with Language Models for Classification of Logical Fallacies},
 year = {2023}
}

@book{staab2010handbook,
 author = {Staab, Steffen and Studer, Rudi},
 doi = {10.1007/978-3-540-24750-0},
 publisher = {Springer Science \& Business Media},
 title = {Handbook on ontologies},
 year = {2010}
}

@article{stork2019semantic,
 author = {Stork, Lise and Weber, Andreas and Miracle, Eul{\`a}lia Gass{\'o} and Verbeek, Fons and Plaat, Aske and van den Herik, Jaap and Wolstencroft, Katherine},
 doi = {10.2139/ssrn.3248498},
 journal = {Journal of Web Semantics},
 pages = {100462},
 publisher = {Elsevier},
 title = {Semantic annotation of natural history collections},
 volume = {59},
 year = {2019}
}

@phdthesis{stork2021knowledge,
 author = {Stork, Lise},
 doi = {10.1109/escience.2018.00113},
 school = {Ph. D. Dissertation, Leiden University},
 title = {Knowledge extraction from archives of natural history collections},
 year = {2021}
}

@article{stork2021large,
 author = {Stork, Lise and Weber, Andreas and van den Herik, Jaap and Plaat, Aske and Verbeek, Fons and Wolstencroft, Katherine},
 doi = {10.1016/j.ecoinf.2021.101222},
 journal = {Ecological informatics},
 pages = {101222},
 publisher = {Elsevier},
 title = {Large-scale zero-shot learning in the wild: Classifying zoological illustrations},
 volume = {62},
 year = {2021}
}

@article{stork2023automated,
 author = {Stork, Lise},
 doi = {10.1145/2509558.2509562},
 journal = {Dagstuhl Reports},
 number = {9},
 pages = {73--75},
 publisher = {Schloss Dagstuhl - Leibniz-centrum f$\{$$\backslash$"u$\}$r Informatik},
 title = {Automated Knowledge Graph Construction},
 volume = {12},
 year = {2023}
}

@article{studer1998knowledge,
 author = {Studer, Rudi and Benjamins, V Richard and Fensel, Dieter},
 doi = {10.1016/s0169-023x(97)00056-6},
 journal = {Data \& knowledge engineering},
 number = {1-2},
 pages = {161--197},
 publisher = {Elsevier},
 title = {Knowledge engineering: Principles and methods},
 volume = {25},
 year = {1998}
}

@incollection{suarez2011neon,
 author = {Su{\'a}rez-Figueroa, Mari Carmen and G{\'o}mez-P{\'e}rez, Asunci{\'o}n and Fern{\'a}ndez-L{\'o}pez, Mariano},
 booktitle = {Ontology engineering in a networked world},
 doi = {10.1109/micai.2011.39},
 pages = {9--34},
 publisher = {Springer},
 title = {The NeOn methodology for ontology engineering},
 year = {2011}
}

@book{suarez2012introduction,
 author = {Su{\'a}rez-Figueroa, Mari Carmen and G{\'o}mez-P{\'e}rez, Asunci{\'o}n and Motta, Enrico and Gangemi, Aldo},
 doi = {10.1007/978-3-642-24794-1_1},
 publisher = {Springer},
 title = {Introduction: Ontology engineering in a networked world},
 year = {2012}
}

@article{sumbul2017fine,
 author = {Sumbul, Gencer and Cinbis, Ramazan Gokberk and Aksoy, Selim},
 doi = {10.1109/siu.2018.8404256},
 journal = {IEEE Transactions on Geoscience and Remote Sensing},
 number = {2},
 pages = {770--779},
 publisher = {IEEE},
 title = {Fine-grained object recognition and zero-shot learning in remote sensing imagery},
 volume = {56},
 year = {2017}
}

@article{sutskever2014sequence,
 author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
 doi = {10.3115/v1/p15-1002},
 journal = {Advances in neural information processing systems},
 title = {Sequence to sequence learning with neural networks},
 volume = {27},
 year = {2014}
}

@article{sutton2019bitter,
 author = {Sutton, Richard},
 doi = {10.1097/00001888-199901001-00001},
 journal = {Incomplete Ideas (blog)},
 number = {1},
 title = {The bitter lesson},
 volume = {13},
 year = {2019}
}

@article{telenius2011biodiversity,
 author = {Telenius, Anders},
 doi = {10.1111/j.1756-1051.2011.01167.x},
 journal = {Nordic Journal of Botany},
 number = {3},
 pages = {378--381},
 publisher = {Wiley Online Library},
 title = {Biodiversity information goes public: GBIF at your service},
 volume = {29},
 year = {2011}
}

@article{tenney2019bert,
 author = {Tenney, Ian and Das, Dipanjan and Pavlick, Ellie},
 doi = {10.18653/v1/p19-1452},
 journal = {arXiv preprint arXiv:1905.05950},
 title = {BERT rediscovers the classical NLP pipeline},
 year = {2019}
}

@article{tiddi2022knowledge,
 author = {Tiddi, Ilaria and Schlobach, Stefan},
 doi = {10.1016/j.artint.2021.103627},
 journal = {Artificial Intelligence},
 pages = {103627},
 publisher = {Elsevier},
 title = {Knowledge graphs as tools for explainable machine learning: A survey},
 volume = {302},
 year = {2022}
}

@article{turpin2023language,
 author = {Turpin, Miles and Michael, Julian and Perez, Ethan and Bowman, Samuel R},
 doi = {10.18653/v1/2021.findings-acl.366},
 journal = {arXiv preprint arXiv:2305.04388},
 title = {Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting},
 year = {2023}
}

@inproceedings{vaithilingam2022expectation,
 author = {Vaithilingam, Priyan and Zhang, Tianyi and Glassman, Elena L},
 booktitle = {Chi conference on human factors in computing systems extended abstracts},
 doi = {10.1145/3491101.3519665},
 pages = {1--7},
 title = {Expectation vs. experience: Evaluating the usability of code generation tools powered by large language models},
 year = {2022}
}

@article{van2019boxology,
 author = {Van Harmelen, Frank and Teije, Annette ten},
 doi = {10.13052/jwe1540-9589.18133},
 journal = {arXiv preprint arXiv:1905.12389},
 title = {A boxology of design patterns for hybrid learning and reasoning systems},
 year = {2019}
}

@article{van2021modular,
 author = {van Bekkum, Michael and de Boer, Maaike and van Harmelen, Frank and Meyer-Vitali, Andr{\'e} and Teije, Annette ten},
 doi = {10.1007/s10489-021-02394-3},
 journal = {Applied Intelligence},
 number = {9},
 pages = {6528--6546},
 publisher = {Springer},
 title = {Modular design patterns for hybrid learning and reasoning systems: a taxonomy, patterns and use cases},
 volume = {51},
 year = {2021}
}

@phdthesis{vanErpNHthesis2010,
 author = {{van Erp}, M.G.J.},
 doi = {10.3115/1693756.1693788},
 isbn = {9789085590279},
 language = {English},
 note = {Series: TiCC Ph.D. Series Volume: 13},
 publisher = {TICC Dissertation Series 13},
 school = {Tilburg University},
 series = {TiCC Ph.D. Series},
 title = {Accessing natural history: Discoveries in data cleaning, structuring, and retrieval},
 year = {2010}
}

@article{vaswani2017attention,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
 doi = {10.18653/v1/p18-1008},
 journal = {Advances in neural information processing systems},
 title = {Attention is all you need},
 volume = {30},
 year = {2017}
}

@article{wang2017origin,
 author = {Wang, Haohan and Raj, Bhiksha},
 doi = {10.1007/978-981-16-3357-7},
 journal = {arXiv preprint arXiv:1702.07800},
 title = {On the origin of deep learning},
 year = {2017}
}

@article{wang2023faithful,
 author = {Wang, Zhuoer and Collins, Marcus and Vedula, Nikhita and Filice, Simone and Malmasi, Shervin and Rokhlenko, Oleg},
 doi = {10.18653/v1/2023.acl-long.160},
 journal = {arXiv preprint arXiv:2305.14793},
 title = {Faithful Low-Resource Data-to-Text Generation through Cycle Training},
 year = {2023}
}

@article{wang2023neural,
 author = {Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others},
 doi = {10.21437/interspeech.2022-10019},
 journal = {arXiv preprint arXiv:2301.02111},
 title = {Neural codec language models are zero-shot text to speech synthesizers},
 year = {2023}
}

@inproceedings{weber2018towards,
 author = {Weber, Andreas and Ameryan, Mahya and Wolstencroft, Katherine and Stork, Lise and Heerlien, Maarten and Schomaker, Lambert},
 booktitle = {Digital Cultural Heritage: Final Conference of the Marie Sk{\l}odowska-Curie Initial Training Network for Digital Cultural Heritage, ITN-DCH 2017, Olimje, Slovenia, May 23--25, 2017, Revised Selected Papers},
 doi = {10.1007/978-3-319-75826-8_13},
 organization = {Springer},
 pages = {155--166},
 title = {Towards a digital infrastructure for illustrated handwritten archives},
 year = {2018}
}

@article{weber2023introduction,
 author = {Weber, Andreas and Heerlien, Maarten and Gass{\'o} Miracle, Eul{\`a}lia and Wolstencroft, Katherine},
 doi = {10.1145/3597459},
 journal = {ACM Journal on Computing and Cultural Heritage},
 number = {1},
 pages = {1--4},
 publisher = {ACM New York, NY},
 title = {Introduction to the Special Issue on Digital Natural and Cultural Heritage: Opportunities and Challenges},
 volume = {16},
 year = {2023}
}

@article{wei2022chain,
 author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
 doi = {10.18653/v1/2023.findings-acl.824},
 journal = {Advances in Neural Information Processing Systems},
 pages = {24824--24837},
 title = {Chain-of-thought prompting elicits reasoning in large language models},
 volume = {35},
 year = {2022}
}

@article{weisz2023toward,
 author = {Weisz, Justin D and Muller, Michael and He, Jessica and Houde, Stephanie},
 doi = {10.1145/3490099.3511119},
 journal = {arXiv preprint arXiv:2301.05578},
 title = {Toward general design principles for generative AI applications},
 year = {2023}
}

@misc{white2023chatgpt,
 archiveprefix = {arXiv},
 author = {Jules White and Sam Hays and Quchen Fu and Jesse Spencer-Smith and Douglas C. Schmidt},
 doi = {10.21437/interspeech.2022-11029},
 eprint = {2303.07839},
 primaryclass = {cs.SE},
 title = {ChatGPT Prompt Patterns for Improving Code Quality, Refactoring, Requirements Elicitation, and Software Design},
 year = {2023}
}

@book{whitehead2017introduction,
 author = {Whitehead, Alfred North},
 doi = {10.1093/oso/9780195002119.001.0001},
 publisher = {Courier Dover Publications},
 title = {An introduction to mathematics},
 year = {2017}
}

@article{wielinga1992kads,
 author = {Wielinga, Bob J and Schreiber, A Th and Breuker, Jost A},
 doi = {10.1016/1042-8143(92)90013-q},
 journal = {Knowledge acquisition},
 number = {1},
 pages = {5--53},
 publisher = {Elsevier},
 title = {KADS: A modelling approach to knowledge engineering},
 volume = {4},
 year = {1992}
}

@article{Wilkinson2016,
 author = {Mark D. Wilkinson and Michel Dumontier and IJsbrand Jan Aalbersberg and Gabrielle Appleton and Myles Axton and Arie Baak and Niklas Blomberg and Jan-Willem Boiten and Luiz Bonino da Silva Santos and Philip E. Bourne and Jildau Bouwman and Anthony J. Brookes and Tim Clark and Merc{\`{e}} Crosas and Ingrid Dillo and Olivier Dumon and Scott Edmunds and Chris T. Evelo and Richard Finkers and Alejandra Gonzalez-Beltran and Alasdair J.G. Gray and Paul Groth and Carole Goble and Jeffrey S. Grethe and Jaap Heringa and Peter A.C 't Hoen and Rob Hooft and Tobias Kuhn and Ruben Kok and Joost Kok and Scott J. Lusher and Maryann E. Martone and Albert Mons and Abel L. Packer and Bengt Persson and Philippe Rocca-Serra and Marco Roos and Rene van Schaik and Susanna-Assunta Sansone and Erik Schultes and Thierry Sengstag and Ted Slater and George Strawn and Morris A. Swertz and Mark Thompson and Johan van der Lei and Erik van Mulligen and Jan Velterop and Andra Waagmeester and Peter Wittenburg and Katherine Wolstencroft and Jun Zhao and Barend Mons},
 doi = {10.1038/sdata.2016.18},
 journal = {Scientific Data},
 month = {March},
 number = {1},
 publisher = {Springer Science and Business Media {LLC}},
 title = {The {FAIR} Guiding Principles for scientific data management and stewardship},
 url = {https://doi.org/10.1038/sdata.2016.18},
 volume = {3},
 year = {2016}
}

@article{wong2023word,
 author = {Wong, Lionel and Grand, Gabriel and Lew, Alexander K and Goodman, Noah D and Mansinghka, Vikash K and Andreas, Jacob and Tenenbaum, Joshua B},
 doi = {10.1109/cvpr.2015.7299068},
 journal = {arXiv preprint arXiv:2306.12672},
 title = {From Word Models to World Models: Translating from Natural Language to the Probabilistic Language of Thought},
 year = {2023}
}

@article{xie2022pre,
 author = {Xie, Qianqian and Bishop, Jennifer Amy and Tiwari, Prayag and Ananiadou, Sophia},
 doi = {10.1016/j.knosys.2022.109460},
 journal = {Knowledge-Based Systems},
 pages = {109460},
 publisher = {Elsevier},
 title = {Pre-trained language models with domain knowledge for biomedical extractive summarization},
 volume = {252},
 year = {2022}
}

@misc{yang2023logical,
 archiveprefix = {arXiv},
 author = {Zonglin Yang and Xinya Du and Rui Mao and Jinjie Ni and Erik Cambria},
 doi = {10.1016/j.inffus.2023.101988},
 eprint = {2303.12023},
 primaryclass = {cs.CL},
 title = {Logical Reasoning over Natural Language as Knowledge Representation: A Survey},
 year = {2023}
}

@article{yoo2021gpt3mix,
 author = {Yoo, Kang Min and Park, Dongju and Kang, Jaewook and Lee, Sang-Woo and Park, Woomyeong},
 doi = {10.18653/v1/2021.findings-emnlp.192},
 journal = {arXiv preprint arXiv:2104.08826},
 title = {GPT3Mix: Leveraging large-scale language models for text augmentation},
 year = {2021}
}

@article{yu2022coca,
 author = {Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
 doi = {10.1109/iccv.2013.269},
 journal = {arXiv preprint arXiv:2205.01917},
 title = {Coca: Contrastive captioners are image-text foundation models},
 year = {2022}
}

@misc{zhang2023using,
 archiveprefix = {arXiv},
 author = {Bohui Zhang and Ioannis Reklos and Nitisha Jain and Albert Meroño Peñuela and Elena Simperl},
 doi = {10.3233/faia230091},
 eprint = {2309.08491},
 primaryclass = {cs.CL},
 title = {Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata},
 year = {2023}
}

@article{zhou2022learning,
 author = {Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
 doi = {10.1109/cvpr52688.2022.01631},
 journal = {International Journal of Computer Vision},
 number = {9},
 pages = {2337--2348},
 publisher = {Springer},
 title = {Learning to prompt for vision-language models},
 volume = {130},
 year = {2022}
}

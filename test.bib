@article{Wilkinson2016,
  doi = {10.1038/sdata.2016.18},
  url = {https://doi.org/10.1038/sdata.2016.18},
  year = {2016},
  month = mar,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {3},
  number = {1},
  author = {Mark D. Wilkinson and Michel Dumontier and IJsbrand Jan Aalbersberg and Gabrielle Appleton and Myles Axton and Arie Baak and Niklas Blomberg and Jan-Willem Boiten and Luiz Bonino da Silva Santos and Philip E. Bourne and Jildau Bouwman and Anthony J. Brookes and Tim Clark and Merc{\`{e}} Crosas and Ingrid Dillo and Olivier Dumon and Scott Edmunds and Chris T. Evelo and Richard Finkers and Alejandra Gonzalez-Beltran and Alasdair J.G. Gray and Paul Groth and Carole Goble and Jeffrey S. Grethe and Jaap Heringa and Peter A.C 't Hoen and Rob Hooft and Tobias Kuhn and Ruben Kok and Joost Kok and Scott J. Lusher and Maryann E. Martone and Albert Mons and Abel L. Packer and Bengt Persson and Philippe Rocca-Serra and Marco Roos and Rene van Schaik and Susanna-Assunta Sansone and Erik Schultes and Thierry Sengstag and Ted Slater and George Strawn and Morris A. Swertz and Mark Thompson and Johan van der Lei and Erik van Mulligen and Jan Velterop and Andra Waagmeester and Peter Wittenburg and Katherine Wolstencroft and Jun Zhao and Barend Mons},
  title = {The {FAIR} Guiding Principles for scientific data management and stewardship},
  journal = {Scientific Data}
}

@article{foundationmodel2021,
  author       = {Rishi Bommasani and et al.},
  title        = {On the Opportunities and Risks of Foundation Models},
  journal      = {CoRR},
  volume       = {abs/2108.07258},
  year         = {2021},
  url          = {https://arxiv.org/abs/2108.07258},
  doi           = {10.48550/arXiv.2108.07258},
  eprinttype    = {arXiv},
  eprint       = {2108.07258},
  timestamp    = {Fri, 17 Feb 2023 09:02:02 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2108-07258.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@misc{white2023chatgpt,
      title={ChatGPT Prompt Patterns for Improving Code Quality, Refactoring, Requirements Elicitation, and Software Design}, 
      author={Jules White and Sam Hays and Quchen Fu and Jesse Spencer-Smith and Douglas C. Schmidt},
      year={2023},
      eprint={2303.07839},
    doi={10.48550/arXiv.2303.07839},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@inproceedings{kgpromptfusion2023,
author = {Zhang, Wen and Zhu, Yushan and Chen, Mingyang and Geng, Yuxia and Huang, Yufeng and Xu, Yajing and Song, Wenting and Chen, Huajun},
title = {Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583301},
doi = {10.1145/3543507.3583301},
abstract = {Knowledge graphs (KG) are essential background knowledge providers in many tasks. When designing models for KG-related tasks, one of the key tasks is to devise the Knowledge Representation and Fusion (KRF) module that learns the representation of elements from KGs and fuses them with task representations. While due to the difference of KGs and perspectives to be considered during fusion across tasks, duplicate and ad hoc KRF modules design are conducted among tasks. In this paper, we propose a novel knowledge graph pretraining model KGTransformer that could serve as a uniform KRF module in diverse KG-related tasks. We pretrain KGTransformer with three self-supervised tasks with sampled sub-graphs as input. For utilization, we propose a general prompt-tuning mechanism regarding task data as a triple prompt to allow flexible interactions between task KGs and task data. We evaluate pretrained KGTransformer on three tasks, triple classification, zero-shot image classification, and question answering. KGTransformer consistently achieves better results than specifically designed task models. Through experiments, we justify that the pretrained KGTransformer could be used off the shelf as a general and effective KRF module across KG-related tasks. The code and datasets are available at https://github.com/zjukg/KGTransformer.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {2581–2590},
numpages = {10},
keywords = {pretrain and fine-tune, knowledge transfer, knowledge graph},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{keywords2023,
author = {Lee, Wanhae and Chun, Minki and Jeong, Hyeonhak and Jung, Hyunggu},
title = {Toward Keyword Generation through Large Language Models},
year = {2023},
isbn = {9798400701078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581754.3584126},
doi = {10.1145/3581754.3584126},
abstract = {It is essential to understand research trends for researchers, decision-makers, and investors. One way to analyze research trends is to collect and analyze author-defined keywords in scientific papers. Unfortunately, while author-defined keywords are beneficial to researchers aiming to figure out the trends of their research fields, 45\% of scientific papers in Microsoft Academic Graph did not contain their author-defined keywords. Additionally, six of the top seven AI conferences neither collect nor disclose keywords. This paper proposes a method for generating the keywords using Galactica, a pre-trained large language model published by Meta. We evaluate this method’s performance by comparing the keywords provided by authors in the CoRL’22 and report characteristics of the generated keywords. Our study shows the F1 score of our proposed method was ten times better than that of previous studies, and 42.7\% of the generated keywords are relevant to author-defined keywords.},
booktitle = {Companion Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {37–40},
numpages = {4},
keywords = {text mining, language model, text generation, keywords},
location = {Sydney, NSW, Australia},
series = {IUI '23 Companion}
}

@inproceedings{bach-etal-2022-promptsource,
    title = "{P}rompt{S}ource: An Integrated Development Environment and Repository for Natural Language Prompts",
    author = "Bach, Stephen  and
      Sanh, Victor  and
      Yong, Zheng Xin  and
      Webson, Albert  and
      Raffel, Colin  and
      Nayak, Nihal V.  and
      Sharma, Abheesht  and
      Kim, Taewoon  and
      Bari, M Saiful  and
      Fevry, Thibault  and
      Alyafeai, Zaid  and
      Dey, Manan  and
      Santilli, Andrea  and
      Sun, Zhiqing  and
      Ben-david, Srulik  and
      Xu, Canwen  and
      Chhablani, Gunjan  and
      Wang, Han  and
      Fries, Jason  and
      Al-shaibani, Maged  and
      Sharma, Shanya  and
      Thakker, Urmish  and
      Almubarak, Khalid  and
      Tang, Xiangru  and
      Radev, Dragomir  and
      Jiang, Mike Tian-jian  and
      Rush, Alexander",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-demo.9",
    doi = {10.18653/v1/2022.acl-demo.9},
    pages = "93--104",
    abstract = "PromptSource is a system for creating, sharing, and using natural language prompts. Prompts are functions that map an example from a dataset to a natural language input and target output. Using prompts to train and query language models is an emerging area in NLP that requires new tools that let users develop and refine these prompts collaboratively. PromptSource addresses the emergent challenges in this new setting with (1) a templating language for defining data-linked prompts, (2) an interface that lets users quickly iterate on prompt development by observing outputs of their prompts on many examples, and (3) a community-driven set of guidelines for contributing new prompts to a common pool. Over 2,000 prompts for roughly 170 datasets are already available in PromptSource. PromptSource is available at https://github.com/bigscience-workshop/promptsource.",
}

@misc{yang2023logical,
      title={Logical Reasoning over Natural Language as Knowledge Representation: A Survey}, 
      author={Zonglin Yang and Xinya Du and Rui Mao and Jinjie Ni and Erik Cambria},
      year={2023},
      eprint={2303.12023},
      doi={10.48550/arXiv.2303.12023},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{studer1998knowledge,
  title={Knowledge engineering: Principles and methods},
  author={Studer, Rudi and Benjamins, V Richard and Fensel, Dieter},
  journal={Data \& knowledge engineering},
  volume={25},
  number={1-2},
  pages={161--197},
  year={1998},
doi = {10.1016/S0169-023X(97)00056-6},
  publisher={Elsevier}
}

@article{nlpPLMSurvey2023, author = {Min, Bonan and Ross, Hayley and Sulem, Elior and Veyseh, Amir Pouran Ben and Nguyen, Thien Huu and Sainz, Oscar and Agirre, Eneko and Heintz, Ilana and Roth, Dan}, title = {Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey}, year = {2023}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, issn = {0360-0300}, url = {https://doi.org/10.1145/3605943}, doi = {10.1145/3605943}, abstract = {Large, pre-trained language models (PLMs) such as BERT and GPT have drastically changed the Natural Language Processing (NLP) field. For numerous NLP tasks, approaches leveraging PLMs have achieved state-of-the-art performance. The key idea is to learn a generic, latent representation of language from a generic task once, then share it across disparate NLP tasks. Language modeling serves as the generic task, one with abundant self-supervised text available for extensive training. This article presents the key fundamental concepts of PLM architectures and a comprehensive view of the shift to PLM-driven NLP techniques. It surveys work applying the pre-training then fine-tuning, prompting, and text generation approaches. In addition, it discusses PLM limitations and suggested directions for future research.}, note = {Just Accepted}, journal = {ACM Comput. Surv.}, month = {jun} }



@misc{schick2023toolformer,
      title={Toolformer: Language Models Can Teach Themselves to Use Tools}, 
      author={Timo Schick and Jane Dwivedi-Yu and Roberto Dessì and Roberta Raileanu and Maria Lomeli and Luke Zettlemoyer and Nicola Cancedda and Thomas Scialom},
      year={2023},
      eprint={2302.04761},
      doi={10.48550/arXiv.2302.04761},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{kung2023performance,
  title={Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models},
  author={Kung, Tiffany H and Cheatham, Morgan and Medenilla, Arielle and Sillos, Czarina and De Leon, Lorie and Elepa{\~n}o, Camille and Madriaga, Maria and Aggabao, Rimel and Diaz-Candido, Giezel and Maningo, James and others},
  journal={PLoS digital health},
  volume={2},
  number={2},
  pages={e0000198},
  year={2023},
  publisher={Public Library of Science}
}

@incollection{gangemi2009ontology,
  title={Ontology design patterns},
  author={Gangemi, Aldo and Presutti, Valentina},
  booktitle={Handbook on ontologies},
  pages={221--243},
  year={2009},
  publisher={Springer}
}

@inproceedings{schreiber2008principles,
  title={Principles for Knowledge Engineering on the Web.},
  author={Schreiber, Guus and Aroyo, Lora},
  booktitle={AAAI Spring Symposium: Symbiotic Relationships between Semantic Web and Knowledge Engineering},
  pages={78--82},
  year={2008}
}

@article{schreiber2008knowledge,
  title={Knowledge engineering},
  author={Schreiber, Guus},
  journal={Foundations of Artificial Intelligence},
  volume={3},
  pages={929--946},
  year={2008},
  publisher={Elsevier}
}

@book{staab2010handbook,
  title={Handbook on ontologies},
  author={Staab, Steffen and Studer, Rudi},
  year={2010},
  publisher={Springer Science \& Business Media}
}

@incollection{chari2020directions,
  title={Directions for Explainable Knowledge-Enabled Systems},
  author={Chari, Shruthi and Gruen, Daniel M and Seneviratne, Oshani and McGuinness, Deborah L},
  booktitle={Knowledge Graphs for eXplainable Artificial Intelligence: Foundations, Applications and Challenges},
  pages={245--261},
  year={2020},
  publisher={IOS Press}
}

@phdthesis{vanErpNHthesis2010,
title = "Accessing natural history: Discoveries in data cleaning, structuring, and retrieval",
author = "{van Erp}, M.G.J.",
note = "Series: TiCC Ph.D. Series Volume: 13",
year = "2010",
language = "English",
isbn = "9789085590279",
school = "Tilburg University",
series = "TiCC Ph.D. Series",
publisher = "TICC Dissertation Series 13",
}

@inproceedings{dovsilovic2018explainable,
  title={Explainable artificial intelligence: A survey},
  author={Do{\v{s}}ilovi{\'c}, Filip Karlo and Br{\v{c}}i{\'c}, Mario and Hlupi{\'c}, Nikica},
  booktitle={2018 41st International convention on information and communication technology, electronics and microelectronics (MIPRO)},
  pages={0210--0215},
  year={2018},
  organization={IEEE}
}

@article{DBLP:journals/corr/abs-2202-01875,
  author       = {Himabindu Lakkaraju and
                  Dylan Slack and
                  Yuxin Chen and
                  Chenhao Tan and
                  Sameer Singh},
  title        = {Rethinking Explainability as a Dialogue: {A} Practitioner's Perspective},
  journal      = {CoRR},
  volume       = {abs/2202.01875},
  year         = {2022},
  url          = {https://arxiv.org/abs/2202.01875},
  eprinttype    = {arXiv},
  eprint       = {2202.01875},
  timestamp    = {Tue, 25 Apr 2023 07:40:33 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2202-01875.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{akata2020research,
  title={A research agenda for hybrid intelligence: augmenting human intellect with collaborative, adaptive, responsible, and explainable artificial intelligence},
  author={Akata, Zeynep and Balliet, Dan and De Rijke, Maarten and Dignum, Frank and Dignum, Virginia and Eiben, Guszti and Fokkens, Antske and Grossi, Davide and Hindriks, Koen and Hoos, Holger and others},
  journal={Computer},
  volume={53},
  number={8},
  pages={18--28},
  year={2020},
  publisher={IEEE}
}


@article{mialon2023augmented,
  title={Augmented language models: a survey},
  author={Mialon, Gr{\'e}goire and Dess{\`\i}, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raileanu, Roberta and Rozi{\`e}re, Baptiste and Schick, Timo and Dwivedi-Yu, Jane and Celikyilmaz, Asli and others},
  journal={arXiv preprint arXiv:2302.07842},
  year={2023}
}

@article{MartinezRodriguez2020,
  doi = {10.3233/sw-180333},
  url = {https://doi.org/10.3233/sw-180333},
  year = {2020},
  month = feb,
  publisher = {{IOS} Press},
  volume = {11},
  number = {2},
  pages = {255--335},
  author = {Jose L. Martinez-Rodriguez and Aidan Hogan and Ivan Lopez-Arevalo},
  editor = {Andreas Hotho},
  title = {Information extraction meets the Semantic Web: A survey},
  journal = {Semantic Web}
}

@book{novaes2012formal,
  title={Formal languages in logic: A philosophical and cognitive analysis},
  author={Novaes, Catarina Dutilh},
  year={2012},
  publisher={Cambridge University Press}
}

@book{carus2007carnap,
  title={Carnap and twentieth-century thought: Explication as enlightenment},
  author={Carus, Andr{\'e} W},
  year={2007},
  publisher={Cambridge University Press}
}

@book{novaes2020dialogical,
  title={The dialogical roots of deduction: Historical, cognitive, and philosophical perspectives on reasoning},
  author={Novaes, Catarina Dutilh},
  year={2020},
  publisher={Cambridge University Press}
}

@article{tiddi2022knowledge,
  title={Knowledge graphs as tools for explainable machine learning: A survey},
  author={Tiddi, Ilaria and Schlobach, Stefan},
  journal={Artificial Intelligence},
  volume={302},
  pages={103627},
  year={2022},
  publisher={Elsevier}
}

@book{whitehead2017introduction,
  title={An introduction to mathematics},
  author={Whitehead, Alfred North},
  year={2017},
  publisher={Courier Dover Publications}
}

@article{menary2007writing,
  title={Writing as thinking},
  author={Menary, Richard},
  journal={Language sciences},
  volume={29},
  number={5},
  pages={621--632},
  year={2007},
  publisher={Elsevier}
}

@inproceedings{groth2023knowledge,
  title={Knowledge Graphs and their Role in the Knowledge Engineering of the 21st Century (Dagstuhl Seminar 22372)},
  author={Groth, Paul and Simperl, Elena and van Erp, Marieke and Vrande{\v{c}}i{\'c}, Denny},
  booktitle={Dagstuhl Reports},
  volume={12},
  number={9},
  year={2023},
  organization={Schloss Dagstuhl-Leibniz-Zentrum f{\"u}r Informatik}
}

@article{sumbul2017fine,
  title={Fine-grained object recognition and zero-shot learning in remote sensing imagery},
  author={Sumbul, Gencer and Cinbis, Ramazan Gokberk and Aksoy, Selim},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={56},
  number={2},
  pages={770--779},
  year={2017},
  publisher={IEEE}
}

@book{suarez2012introduction,
  title={Introduction: Ontology engineering in a networked world},
  author={Su{\'a}rez-Figueroa, Mari Carmen and G{\'o}mez-P{\'e}rez, Asunci{\'o}n and Motta, Enrico and Gangemi, Aldo},
  year={2012},
  publisher={Springer}
}

@book{kendall2019ontology,
  title={Ontology engineering},
  author={Kendall, Elisa F and McGuinness, Deborah L},
  year={2019},
  publisher={Morgan \& Claypool Publishers}
}

@inproceedings{de2012nichesourcing,
  title={Nichesourcing: harnessing the power of crowds of experts},
  author={De Boer, Victor and Hildebrand, Michiel and Aroyo, Lora and De Leenheer, Pieter and Dijkshoorn, Chris and Tesfa, Binyam and Schreiber, Guus},
  booktitle={Knowledge Engineering and Knowledge Management: 18th International Conference, EKAW 2012, Galway City, Ireland, October 8-12, 2012. Proceedings 18},
  pages={16--20},
  year={2012},
  organization={Springer}
}

@techreport{baskauf2017tdwg,
  title={TDWG Standards Documentation Specification},
  author={Baskauf, Steve and Hyam, Roger and Blum, Stanley and Morris, Robert A and Rees, Jonathan and Sachs, Joel and Whitbread, Greg and Wieczorek, John},
  year={2017},
  institution={Biodiversity Information Standards (TDWG)}
}

@article{page2008biodiversity,
  title={Biodiversity informatics: the challenge of linking data and the role of shared identifiers},
  author={Page, Roderic DM},
  journal={Briefings in bioinformatics},
  volume={9},
  number={5},
  pages={345--354},
  year={2008},
  publisher={Oxford University Press}
}

@article{blagoderov2012no,
  title={No specimen left behind: industrial scale digitization of natural history collections},
  author={Blagoderov, Vladimir and Kitching, Ian J and Livermore, Laurence and Simonsen, Thomas J and Smith, Vincent S},
  journal={ZooKeys},
  volume={209},
  pages={133--146},
  year={2012},
  publisher={Pensoft Publishers}
}

@article{yoo2021gpt3mix,
  title={GPT3Mix: Leveraging large-scale language models for text augmentation},
  author={Yoo, Kang Min and Park, Dongju and Kang, Jaewook and Lee, Sang-Woo and Park, Woomyeong},
  journal={arXiv preprint arXiv:2104.08826},
  year={2021}
}

@article{stork2021large,
  title={Large-scale zero-shot learning in the wild: Classifying zoological illustrations},
  author={Stork, Lise and Weber, Andreas and van den Herik, Jaap and Plaat, Aske and Verbeek, Fons and Wolstencroft, Katherine},
  journal={Ecological informatics},
  volume={62},
  pages={101222},
  year={2021},
  publisher={Elsevier}
}

@article{petroni2019language,
  title={Language models as knowledge bases?},
  author={Petroni, Fabio and Rockt{\"a}schel, Tim and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander H and Riedel, Sebastian},
  journal={arXiv preprint arXiv:1909.01066},
  year={2019}
}

@inproceedings{jain2022jigsaw,
  title={Jigsaw: Large language models meet program synthesis},
  author={Jain, Naman and Vaidyanath, Skanda and Iyer, Arun and Natarajan, Nagarajan and Parthasarathy, Suresh and Rajamani, Sriram and Sharma, Rahul},
  booktitle={Proceedings of the 44th International Conference on Software Engineering},
  pages={1219--1231},
  year={2022}
}

@inproceedings{bosselut2019comet,
    title = "{COMET}: Commonsense Transformers for Automatic Knowledge Graph Construction",
    author = "Bosselut, Antoine  and
      Rashkin, Hannah  and
      Sap, Maarten  and
      Malaviya, Chaitanya  and
      Celikyilmaz, Asli  and
      Choi, Yejin",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1470",
    doi = "10.18653/v1/P19-1470",
    pages = "4762--4779",
    abstract = "We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5{\%} (ATOMIC) and 91.7{\%} (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods.",
}

@article{alkhamissi2022review,
  title={A review on language models as knowledge bases},
  author={AlKhamissi, Badr and Li, Millicent and Celikyilmaz, Asli and Diab, Mona and Ghazvininejad, Marjan},
  journal={arXiv preprint arXiv:2204.06031},
  year={2022}
}

@article{dutilh2017carnapian,
  title={Carnapian explication, formalisms as cognitive tools, and the paradox of adequate formalization},
  author={Dutilh Novaes, Catarina and Reck, Erich},
  journal={Synthese},
  volume={194},
  pages={195--215},
  year={2017},
  publisher={Springer}
}

@article{shanahan2022talking,
  title={Talking About Large Language Models},
  author={Shanahan, Murray},
  journal={arXiv preprint arXiv:2212.03551},
  year={2022}
}

@article{mahowald2023dissociating,
  title={Dissociating language and thought in large language models: a cognitive perspective},
  author={Mahowald, Kyle and Ivanova, Anna A and Blank, Idan A and Kanwisher, Nancy and Tenenbaum, Joshua B and Fedorenko, Evelina},
  journal={arXiv preprint arXiv:2301.06627},
  year={2023}
}

@article{cohen2023crawling,
  title={Crawling the Internal Knowledge-Base of Language Models},
  author={Cohen, Roi and Geva, Mor and Berant, Jonathan and Globerson, Amir},
  journal={arXiv preprint arXiv:2301.12810},
  year={2023}
}

@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM Computing Surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023},
  publisher={ACM New York, NY}
}

@article{pan2023unifying,
  title={Unifying Large Language Models and Knowledge Graphs: A Roadmap},
  author={Pan, Shirui and Luo, Linhao and Wang, Yufei and Chen, Chen and Wang, Jiapu and Wu, Xindong},
  journal={arXiv preprint arXiv:2306.08302},
  year={2023}
}

@article{razniewski2021language,
  title={Language models as or for knowledge bases},
  author={Razniewski, Simon and Yates, Andrew and Kassner, Nora and Weikum, Gerhard},
  journal={arXiv preprint arXiv:2110.04888},
  year={2021}
}

@article{wong2023word,
  title={From Word Models to World Models: Translating from Natural Language to the Probabilistic Language of Thought},
  author={Wong, Lionel and Grand, Gabriel and Lew, Alexander K and Goodman, Noah D and Mansinghka, Vikash K and Andreas, Jacob and Tenenbaum, Joshua B},
  journal={arXiv preprint arXiv:2306.12672},
  year={2023}
}

@article{breit2023combining,
  title={Combining machine learning and semantic web: A systematic mapping study},
  author={Breit, Anna and Waltersdorfer, Laura and Ekaputra, Fajar J and Sabou, Marta and Ekelhart, Andreas and Iana, Andreea and Paulheim, Heiko and Portisch, Jan and Revenko, Artem and Teije, Annette ten and others},
  journal={ACM Computing Surveys},
  year={2023},
  publisher={ACM New York, NY}
}

@inproceedings{ekaputra2023describing,
  title={Describing and Organizing Semantic Web and Machine Learning Systems in the SWeMLS-KG},
  author={Ekaputra, Fajar J and Llugiqi, Majlinda and Sabou, Marta and Ekelhart, Andreas and Paulheim, Heiko and Breit, Anna and Revenko, Artem and Waltersdorfer, Laura and Farfar, Kheir Eddine and Auer, S{\"o}ren},
  booktitle={European Semantic Web Conference},
  pages={372--389},
  year={2023},
  organization={Springer}
}

@article{hardisty2022digital,
  title={Digital extended specimens: Enabling an extensible network of biodiversity data records as integrated digital objects on the internet},
  author={Hardisty, Alex R and Ellwood, Elizabeth R and Nelson, Gil and Zimkus, Breda and Buschbom, Jutta and Addink, Wouter and Rabeler, Richard K and Bates, John and Bentley, Andrew and Fortes, Jos{\'e} AB and others},
  journal={BioScience},
  volume={72},
  number={10},
  pages={978--987},
  year={2022},
  publisher={Oxford University Press}
}

@article{godfray2002challenges,
  title={Challenges for taxonomy},
  author={Godfray, H Charles J},
  journal={Nature},
  volume={417},
  number={6884},
  pages={17--19},
  year={2002},
  publisher={Nature Publishing Group UK London}
}

@book{macgregor2018naturalists,
  title={Naturalists in the field: collecting, recording and preserving the natural world from the fifteenth to the twenty-first century},
  author={MacGregor, Arthur},
  volume={2},
  year={2018},
  publisher={Brill}
}
@inproceedings{weber2018towards,
  title={Towards a digital infrastructure for illustrated handwritten archives},
  author={Weber, Andreas and Ameryan, Mahya and Wolstencroft, Katherine and Stork, Lise and Heerlien, Maarten and Schomaker, Lambert},
  booktitle={Digital Cultural Heritage: Final Conference of the Marie Sk{\l}odowska-Curie Initial Training Network for Digital Cultural Heritage, ITN-DCH 2017, Olimje, Slovenia, May 23--25, 2017, Revised Selected Papers},
  pages={155--166},
  year={2018},
  organization={Springer}
}

@article{kapli2020phylogenetic,
  title={Phylogenetic tree building in the genomic age},
  author={Kapli, Paschalia and Yang, Ziheng and Telford, Maximilian J},
  journal={Nature Reviews Genetics},
  volume={21},
  number={7},
  pages={428--444},
  year={2020},
  publisher={Nature Publishing Group UK London}
}
@inproceedings{oosterman2014crowdsourcing,
  title={Crowdsourcing knowledge-intensive tasks in cultural heritage},
  author={Oosterman, Jasper and Nottamkandath, Archana and Dijkshoorn, Chris and Bozzon, Alessandro and Houben, Geert-Jan and Aroyo, Lora},
  booktitle={Proceedings of the 2014 ACM conference on Web science},
  pages={267--268},
  year={2014}
}
@inproceedings{presutti2009extreme,
  title={eXtreme design with content ontology design patterns},
  author={Presutti, Valentina and Daga, Enrico and Gangemi, Aldo and Blomqvist, Eva},
  booktitle={Proc. Workshop on Ontology Patterns},
  pages={83--97},
  year={2009}
}

@incollection{suarez2011neon,
  title={The NeOn methodology for ontology engineering},
  author={Su{\'a}rez-Figueroa, Mari Carmen and G{\'o}mez-P{\'e}rez, Asunci{\'o}n and Fern{\'a}ndez-L{\'o}pez, Mariano},
  booktitle={Ontology engineering in a networked world},
  pages={9--34},
  year={2011},
  publisher={Springer}
}

@phdthesis{stork2021knowledge,
  title={Knowledge extraction from archives of natural history collections},
  author={Stork, Lise},
  year={2021},
  school={Ph. D. Dissertation, Leiden University}
}

@article{weber2023introduction,
  title={Introduction to the Special Issue on Digital Natural and Cultural Heritage: Opportunities and Challenges},
  author={Weber, Andreas and Heerlien, Maarten and Gass{\'o} Miracle, Eul{\`a}lia and Wolstencroft, Katherine},
  journal={ACM Journal on Computing and Cultural Heritage},
  volume={16},
  number={1},
  pages={1--4},
  year={2023},
  publisher={ACM New York, NY}
}

@article{hedrick2020digitization,
  title={Digitization and the future of natural history collections},
  author={Hedrick, Brandon P and Heberling, J Mason and Meineke, Emily K and Turner, Kathryn G and Grassa, Christopher J and Park, Daniel S and Kennedy, Jonathan and Clarke, Julia A and Cook, Joseph A and Blackburn, David C and others},
  journal={BioScience},
  volume={70},
  number={3},
  pages={243--251},
  year={2020},
  publisher={Oxford University Press}
}


@article{muller2017names,
	Author = {M{\"u}ller-Wille, Staffan},
	Journal = {Osiris},
	Number = {1},
	Pages = {109--128},
	Publisher = {University of Chicago Press Chicago, IL},
	Title = {Names and Numbers:``Data'' in Classical Natural History, 1758--1859},
	Volume = {32},
	Year = {2017}
}

@article{ortolja2022encoding,
  title={Encoding the haunting of an object catalogue: on the potential of digital technologies to perpetuate or subvert the silence and bias of the early-modern archive},
  author={Ortolja-Baird, Alexandra and Nyhan, Julianne},
  journal={Digital Scholarship in the Humanities},
  volume={37},
  number={3},
  pages={844--867},
  year={2022},
  publisher={Oxford University Press}
}

@article{van2019boxology,
  title={A boxology of design patterns for hybrid learning and reasoning systems},
  author={Van Harmelen, Frank and Teije, Annette ten},
  journal={arXiv preprint arXiv:1905.12389},
  year={2019}
}

@article{daga2023data,
  title={Data journeys: explaining AI workflows through abstraction},
  author={Daga, Enrico and Groth, Paul},
  journal={Semantic Web},
  volume={Preprint},
  pages={1--27},
  year={2023},
  publisher={IOS Press}
}

@book{schreiber2000knowledge,
  title={Knowledge engineering and management: the CommonKADS methodology},
  author={Schreiber, Guus and Akkermans, Hans and Anjewierden, Anjo and Shadbolt, Nigel and de Hoog, Robert and Van de Velde, Walter and Wielinga, Bob},
  year={2000},
  publisher={MIT press}
}

@article{miracle2020natuurkundige,
  title={Natuurkundige Commissie Archives Online (Visual edition)},
  author={Miracle, Eul{\`a}lia Gass{\'o} and Stork, Lise and Weber, Andreas and Ameryan, Mahya and Wolstencroft, Katherine},
  year={2020}
}
@article{gwinn2009biodiversity,
  title={The Biodiversity Heritage Library: sharing biodiversity literature with the world},
  author={Gwinn, Nancy E and Rinaldo, Constance},
  journal={IFLA journal},
  volume={35},
  number={1},
  pages={25--34},
  year={2009},
  publisher={Sage Publications Sage UK: London, England}
}
@inproceedings{dijkshoorn2013personalized,
  title={Personalized Nichesourcing: Acquisition of Qualitative Annotations from Niche Communities.},
  author={Dijkshoorn, Chris and Leyssen, Mieke HR and Nottamkandath, Archana and Oosterman, Jasper and Traub, Myriam C and Aroyo, Lora and Bozzon, Alessandro and Fokkink, Wan J and Houben, Geert-Jan and Hovelmann, Henrike and others},
  booktitle={UMAP Workshops},
  year={2013}
}

@article{stork2019semantic,
  title={Semantic annotation of natural history collections},
  author={Stork, Lise and Weber, Andreas and Miracle, Eul{\`a}lia Gass{\'o} and Verbeek, Fons and Plaat, Aske and van den Herik, Jaap and Wolstencroft, Katherine},
  journal={Journal of Web Semantics},
  volume={59},
  pages={100462},
  year={2019},
  publisher={Elsevier}
}

@article{telenius2011biodiversity,
  title={Biodiversity information goes public: GBIF at your service},
  author={Telenius, Anders},
  journal={Nordic Journal of Botany},
  volume={29},
  number={3},
  pages={378--381},
  year={2011},
  publisher={Wiley Online Library}
}

@article{robertson2014gbif,
  title={The GBIF integrated publishing toolkit: facilitating the efficient publishing of biodiversity data on the internet},
  author={Robertson, Tim and D{\"o}ring, Markus and Guralnick, Robert and Bloom, David and Wieczorek, John and Braak, Kyle and Otegui, Javier and Russell, Laura and Desmet, Peter},
  journal={PloS one},
  volume={9},
  number={8},
  pages={e102623},
  year={2014},
  publisher={Public Library of Science San Francisco, USA}
}

@article{allen2023identifying,
  title={Identifying and Consolidating Knowledge Engineering Requirements},
  author={Allen, Bradley P and Ilievski, Filip and Joshi, Saurav},
  journal={arXiv preprint arXiv:2306.15124},
  year={2023}
}

@book{cappelen2021making,
  title={Making AI intelligible: Philosophical foundations},
  author={Cappelen, Herman and Dever, Josh},
  year={2021},
  publisher={Oxford University Press}
}

@book{crawford2021atlas,
  title={The atlas of AI: Power, politics, and the planetary costs of artificial intelligence},
  author={Crawford, Kate},
  year={2021},
  publisher={Yale University Press}
}

@inproceedings{bender2021dangers,
  title={On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
  author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle={Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  pages={610--623},
  year={2021}
}

@article{allen2023brief,
  title={A Brief History of Knowledge Engineering: A Practitioner’s Perspective},
  author={Allen, Bradley P},
  journal={Dagstuhl Reports},
  volume={12},
  number={9},
  pages={65--72},
  year={2023},
  publisher={Schloss Dagstuhl - Leibniz-centrum f$\{$$\backslash$"u$\}$r Informatik}
}

@article{stork2023automated,
  title={Automated Knowledge Graph Construction},
  author={Stork, Lise},
  journal={Dagstuhl Reports},
  volume={12},
  number={9},
  pages={73--75},
  year={2023},
  publisher={Schloss Dagstuhl - Leibniz-centrum f$\{$$\backslash$"u$\}$r Informatik}
}

@article{groth2023forms,
  title={Knowledge Graphs vs. Other Forms of Knowledge Representation},
  author={ Groth, Paul and Hogan, Aidan and Stork, Lise and Thornton, Katherine and Vrandečić Denny},
  journal={Dagstuhl Reports},
  volume={12},
  number={9},
  pages={101--105},
  year={2023},
  publisher={Schloss Dagstuhl - Leibniz-centrum f$\{$$\backslash$"u$\}$r Informatik}
}

@article{simperl2023knowledge,
  title={Knowledge Engineering with Language Models and Neural Methods},
  author={Simperl, Elena and Groth, Paul and Staab, Steffen and Sabou, Marta and Blomqvist, Eva and Allen, Bradley},
  journal={Dagstuhl Reports},
  volume={12},
  number={9},
  pages={93--96},
  year={2023},
  publisher={Schloss Dagstuhl - Leibniz-centrum f$\{$$\backslash$"u$\}$r Informatik}
}

@article{madaan2023self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={arXiv preprint arXiv:2303.17651},
  year={2023}
}

@article{saunders2022self,
  title={Self-critiquing models for assisting human evaluators},
  author={Saunders, William and Yeh, Catherine and Wu, Jeff and Bills, Steven and Ouyang, Long and Ward, Jonathan and Leike, Jan},
  journal={arXiv preprint arXiv:2206.05802},
  year={2022}
}

@article{turpin2023language,
  title={Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting},
  author={Turpin, Miles and Michael, Julian and Perez, Ethan and Bowman, Samuel R},
  journal={arXiv preprint arXiv:2305.04388},
  year={2023}
}

@article{ji2023survey,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  volume={55},
  number={12},
  pages={1--38},
  year={2023},
  publisher={ACM New York, NY}
}

@article{bonner2022review,
  title={A review of biomedical datasets relating to drug discovery: a knowledge graph perspective},
  author={Bonner, Stephen and Barrett, Ian P and Ye, Cheng and Swiers, Rowan and Engkvist, Ola and Bender, Andreas and Hoyt, Charles Tapley and Hamilton, William L},
  journal={Briefings in Bioinformatics},
  volume={23},
  number={6},
  pages={bbac404},
  year={2022},
  publisher={Oxford University Press}
}

@article{annurev-biodatasci-010820-091627,
author = {Callahan, Tiffany J. and Tripodi, Ignacio J. and Pielke-Lombardo, Harrison and Hunter, Lawrence E.},
title = {Knowledge-Based Biomedical Data Science},
journal = {Annual Review of Biomedical Data Science},
volume = {3},
number = {1},
pages = {23-41},
year = {2020},
doi = {10.1146/annurev-biodatasci-010820-091627},
}

@article{badue2021self,
  title={Self-driving cars: A survey},
  author={Badue, Claudine and Guidolini, R{\^a}nik and Carneiro, Raphael Vivacqua and Azevedo, Pedro and Cardoso, Vinicius B and Forechi, Avelino and Jesus, Luan and Berriel, Rodrigo and Paixao, Thiago M and Mutz, Filipe and others},
  journal={Expert Systems with Applications},
  volume={165},
  pages={113816},
  year={2021},
  publisher={Elsevier}
}



@article{rodriguez2020lynx,
  title={Lynx: Towards a legal knowledge graph for multilingual europe},
  author={Rodr{\'\i}guez-Doncel, V{\'\i}ctor and Montiel-Ponsoda, Elena},
  journal={Law Context: A Socio-Legal J.},
  volume={37},
  pages={175},
  year={2020},
  publisher={HeinOnline}
}

@article{hjorland2008knowledge,
  title={What is knowledge organization (KO)?},
  author={Hj{\o}rland, Birger},
  journal={KO Knowledge Organization},
  volume={35},
  number={2-3},
  pages={86--101},
  year={2008},
  publisher={Nomos Verlagsgesellschaft mbH \& Co. KG}
}

@inproceedings{alivanistos2022prompting,
title = "Prompting as Probing: Using Language Models for Knowledge Base Construction",
author = "Dimitrios Alivanistos and Santamar{\'i}a, {Selene B{\'a}ez} and Michael Cochez and Kalo, {Jan Christoph} and {van Krieken}, Emile and Thiviyan Thanapalasingam",
year = "2022",
language = "English",
series = "CEUR Workshop Proceedings",
publisher = "CEUR-WS.org",
pages = "11--34",
editor = "Sneha Singhania and Tuan-Phong Nguyen and Simon Razniewski",
booktitle = "LM-KBC 2022 Knowledge Base Construction from Pre-trained Language Models 2022",
}

@article{pretrainpromptpredict2023,
author = {Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
title = {Pre-Train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {9},
issn = {0360-0300},
url = {https://doi.org/10.1145/3560815},
doi = {10.1145/3560815},
abstract = {This article surveys and organizes research works in a new paradigm in natural language processing, which we dub “prompt-based learning.” Unlike traditional supervised learning, which trains a model to take in an input x and predict an output y as P(y|x), prompt-based learning is based on language models that model the probability of text directly. To use these models to perform prediction tasks, the original input x is modified using a template into a textual string prompt x′ that has some unfilled slots, and then the language model is used to probabilistically fill the unfilled information to obtain a final string x̂, from which the final output y can be derived. This framework is powerful and attractive for a number of reasons: It allows the language model to be pre-trained on massive amounts of raw text, and by defining a new prompting function the model is able to perform few-shot or even zero-shot learning, adapting to new scenarios with few or no labeled data. In this article, we introduce the basics of this promising paradigm, describe a unified set of mathematical notations that can cover a wide variety of existing work, and organize existing work along several dimensions, e.g.,&nbsp;the choice of pre-trained language models, prompts, and tuning strategies. To make the field more accessible to interested beginners, we not only make a systematic review of existing works and a highly structured typology of prompt-based concepts but also release other resources, e.g., a website including constantly updated survey and paperlist.},
journal = {ACM Comput. Surv.},
month = {jan},
articleno = {195},
numpages = {35},
keywords = {prompting, Pre-trained language models}
}

@article{creswell2022selection,
  title={Selection-inference: Exploiting large language models for interpretable logical reasoning},
  author={Creswell, Antonia and Shanahan, Murray and Higgins, Irina},
  journal={arXiv preprint arXiv:2205.09712},
  year={2022}
}

@article{gurrapu2023rationalization,
  title={Rationalization for explainable nlp: A survey},
  author={Gurrapu, Sai and Kulkarni, Ajay and Huang, Lifu and Lourentzou, Ismini and Freeman, Laura and Batarseh, Feras A},
  journal={arXiv preprint arXiv:2301.08912},
  year={2023}
}

@article{weisz2023toward,
  title={Toward general design principles for generative AI applications},
  author={Weisz, Justin D and Muller, Michael and He, Jessica and Houde, Stephanie},
  journal={arXiv preprint arXiv:2301.05578},
  year={2023}
}

@article{newell1982knowledge,
  title={The knowledge level},
  author={Newell, Allen},
  journal={Artificial intelligence},
  volume={18},
  number={1},
  pages={87--127},
  year={1982},
  publisher={Elsevier}
}

@article{sutton2019bitter,
  title={The bitter lesson},
  author={Sutton, Richard},
  journal={Incomplete Ideas (blog)},
  volume={13},
  number={1},
  year={2019}
}

@inproceedings{reynolds2021prompt,
  title={Prompt programming for large language models: Beyond the few-shot paradigm},
  author={Reynolds, Laria and McDonell, Kyle},
  booktitle={Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--7},
  year={2021}
}

@phdthesis{neon2010,
  added-at = {2011-06-10T09:04:03.000+0200},
  address = {Madrid, Spain},
  author = {del Carmen Su\'{a}rez de Figueroa Baonza, Mar\'{i}a},
  biburl = {https://www.bibsonomy.org/bibtex/2688a2eb655c9df88f801cb3b4821809e/bluedolphin},
  interhash = {073c26cc3b5cb9971202803e0d47186e},
  intrahash = {688a2eb655c9df88f801cb3b4821809e},
  keywords = {imported},
  month = jun,
  owner = {braun},
  school = {Universidad Polit\'{e}cnica de Madrid},
  timestamp = {2011-06-10T09:04:13.000+0200},
  title = {NeOn Methodology for Building Ontology Networks: Specification, Scheduling
	and Reuse},
  url = {http://oa.upm.es/3879/2/MARIA_DEL-_CARMEN_SUAREZ_DE_FIGUEROA_BAONZA.pdf},
  year = 2010
}

@article{hogan2021knowledge,
  title={Knowledge graphs},
  author={Hogan, Aidan and Blomqvist, Eva and Cochez, Michael and d’Amato, Claudia and Melo, Gerard de and Gutierrez, Claudio and Kirrane, Sabrina and Gayo, Jos{\'e} Emilio Labra and Navigli, Roberto and Neumaier, Sebastian and others},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={4},
  pages={1--37},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@book{feigenbaum1992personal,
  title={A personal view of expert systems: Looking back and looking ahead},
  author={Feigenbaum, Edward A},
  year={1992},
  publisher={Knowledge Systems Laboratory, Department of Computer Science, Stanford~…}
}

@article{FEIGENBAUM1984,
  doi = {10.1111/j.1749-6632.1984.tb16513.x},
  url = {https://doi.org/10.1111/j.1749-6632.1984.tb16513.x},
  year = {1984},
  month = nov,
  publisher = {Wiley},
  volume = {426},
  number = {1 Computer Cult},
  pages = {91--107},
  author = {EDWARD A. FEIGENBAUM},
  title = {Knowledge Engineering.},
  journal = {Annals of the New York Academy of Sciences}
}

@article{van2021modular,
  title={Modular design patterns for hybrid learning and reasoning systems: a taxonomy, patterns and use cases},
  author={van Bekkum, Michael and de Boer, Maaike and van Harmelen, Frank and Meyer-Vitali, Andr{\'e} and Teije, Annette ten},
  journal={Applied Intelligence},
  volume={51},
  number={9},
  pages={6528--6546},
  year={2021},
  publisher={Springer}
}

@article{gehrmann2021gem,
  title={The gem benchmark: Natural language generation, its evaluation and metrics},
  author={Gehrmann, Sebastian and Adewumi, Tosin and Aggarwal, Karmanya and Ammanamanchi, Pawan Sasanka and Anuoluwapo, Aremu and Bosselut, Antoine and Chandu, Khyathi Raghavi and Clinciu, Miruna and Das, Dipanjan and Dhole, Kaustubh D and others},
  journal={arXiv preprint arXiv:2102.01672},
  year={2021}
}

@article{guo2020cyclegt,
  title={Cyclegt: Unsupervised graph-to-text and text-to-graph generation via cycle training},
  author={Guo, Qipeng and Jin, Zhijing and Qiu, Xipeng and Zhang, Weinan and Wipf, David and Zhang, Zheng},
  journal={arXiv preprint arXiv:2006.04702},
  year={2020}
}

@article{zhou2022learning,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={International Journal of Computer Vision},
  volume={130},
  number={9},
  pages={2337--2348},
  year={2022},
  publisher={Springer}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@inproceedings{booch2021thinking,
  title={Thinking fast and slow in AI},
  author={Booch, Grady and Fabiano, Francesco and Horesh, Lior and Kate, Kiran and Lenchner, Jonathan and Linck, Nick and Loreggia, Andreas and Murgesan, Keerthiram and Mattei, Nicholas and Rossi, Francesca and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  pages={15042--15046},
  year={2021}
}

@article{glymour1998ramon,
  title={Ram{\'o}n Lull and the infidels},
  author={Glymour, Clark and Ford, Kenneth M and Hayes, Patrick J},
  journal={AI Magazine},
  volume={19},
  number={2},
  pages={136--136},
  year={1998}
}

@article{sarker2021deep,
  title={Deep learning: a comprehensive overview on techniques, taxonomy, applications and research directions},
  author={Sarker, Iqbal H},
  journal={SN Computer Science},
  volume={2},
  number={6},
  pages={420},
  year={2021},
  publisher={Springer}
}

@article{shadbolt2015knowledge,
  title={Knowledge elicitation},
  author={Shadbolt, Nigel R and Smart, Paul R and Wilson, J and Sharples, S},
  journal={Evaluation of human work},
  pages={163--200},
  year={2015},
  publisher={CRC Press}
}

@article{xie2022pre,
  title={Pre-trained language models with domain knowledge for biomedical extractive summarization},
  author={Xie, Qianqian and Bishop, Jennifer Amy and Tiwari, Prayag and Ananiadou, Sophia},
  journal={Knowledge-Based Systems},
  volume={252},
  pages={109460},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{alt2019fine,
  title={Fine-tuning Pre-Trained Transformer Language Models to Distantly Supervised Relation Extraction},
  author={Alt, Christoph and H{\"u}bner, Marc and Hennig, Leonhard},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={1388--1398},
  year={2019}
}
@inproceedings{bezerra2013evaluating,
  title={Evaluating ontologies with competency questions},
  author={Bezerra, Camila and Freitas, Fred and Santana, Filipe},
  booktitle={2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)},
  volume={3},
  pages={284--285},
  year={2013},
  organization={IEEE}
}

@article{chang2023survey,
  title={A Survey on Evaluation of Large Language Models},
  author={Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Zhu, Kaijie and Chen, Hao and Yang, Linyi and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others},
  journal={arXiv preprint arXiv:2307.03109},
  year={2023}
}

@article{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph C and Cai, Carrie J and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  journal={arXiv preprint arXiv:2304.03442},
  year={2023}
}

@book{mercier2017enigma,
  title={The enigma of reason},
  author={Mercier, Hugo and Sperber, Dan},
  year={2017},
  publisher={Harvard University Press}
}

@article{menary2010dimensions,
  title={Dimensions of mind},
  author={Menary, Richard},
  journal={Phenomenology and the Cognitive Sciences},
  volume={9},
  pages={561--578},
  year={2010},
  publisher={Springer}
}

@book{gabbay2004rise,
  title={The rise of modern logic: from Leibniz to Frege},
  author={Gabbay, Dov M and Woods, John},
  year={2004},
  publisher={Elsevier}
}

@book{kahneman2011thinking,
  title={Thinking, fast and slow},
  author={Kahneman, Daniel},
  year={2011},
  publisher={macmillan}
}

@inproceedings{feigenbaum1977art,
  title={The art of artificial intelligence: Themes and case studies of knowledge engineering},
  author={Feigenbaum, Edward A},
  booktitle={Proceedings of the Fifth International Joint Conference on Artificial Intelligence},
  volume={2},
  year={1977},
  organization={Boston}
}

@article{berners2001semantic,
  title={The semantic web},
  author={Berners-Lee, Tim and Hendler, James and Lassila, Ora},
  journal={Scientific american},
  volume={284},
  number={5},
  pages={34--43},
  year={2001},
  publisher={JSTOR}
}

@book{hendler2020semantic,
  title={Semantic web for the working ontologist: Effective modeling for linked data, RDFS, and OWL},
  author={Hendler, James and Gandon, Fabien and Allemang, Dean},
  year={2020},
  publisher={Morgan \& Claypool}
}

@article{wang2017origin,
  title={On the origin of deep learning},
  author={Wang, Haohan and Raj, Bhiksha},
  journal={arXiv preprint arXiv:1702.07800},
  year={2017}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@article{tenney2019bert,
  title={BERT rediscovers the classical NLP pipeline},
  author={Tenney, Ian and Das, Dipanjan and Pavlick, Ellie},
  journal={arXiv preprint arXiv:1905.05950},
  year={2019}
}

@article{austin2021program,
  title={Program synthesis with large language models},
  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
  journal={arXiv preprint arXiv:2108.07732},
  year={2021}
}

@inproceedings{vaithilingam2022expectation,
  title={Expectation vs. experience: Evaluating the usability of code generation tools powered by large language models},
  author={Vaithilingam, Priyan and Zhang, Tianyi and Glassman, Elena L},
  booktitle={Chi conference on human factors in computing systems extended abstracts},
  pages={1--7},
  year={2022}
}

@inproceedings{hulsebos2019sherlock,
  title={Sherlock: A deep learning approach to semantic data type detection},
  author={Hulsebos, Madelon and Hu, Kevin and Bakker, Michiel and Zgraggen, Emanuel and Satyanarayan, Arvind and Kraska, Tim and Demiralp, {\c{C}}agatay and Hidalgo, C{\'e}sar},
  booktitle={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={1500--1508},
  year={2019}
}

@article{korini2023column,
  title={Column Type Annotation using ChatGPT},
  author={Korini, Keti and Bizer, Christian},
  journal={arXiv preprint arXiv:2306.00745},
  year={2023}
}

@article{axelsson2023using,
  title={Using Large Language Models for Zero-Shot Natural Language Generation from Knowledge Graphs},
  author={Axelsson, Agnes and Skantze, Gabriel},
  journal={arXiv preprint arXiv:2307.07312},
  year={2023}
}

@article{lorandi2023data,
  title={Data-to-text Generation for Severely Under-Resourced Languages with GPT-3.5: A Bit of Help Needed from Google Translate},
  author={Lorandi, Michela and Belz, Anya},
  journal={arXiv preprint arXiv:2308.09957},
  year={2023}
}

@article{wang2023faithful,
  title={Faithful Low-Resource Data-to-Text Generation through Cycle Training},
  author={Wang, Zhuoer and Collins, Marcus and Vedula, Nikhita and Filice, Simone and Malmasi, Shervin and Rokhlenko, Oleg},
  journal={arXiv preprint arXiv:2305.14793},
  year={2023}
}

@article{goodfellow2020generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Communications of the ACM},
  volume={63},
  number={11},
  pages={139--144},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@article{yu2022coca,
  title={Coca: Contrastive captioners are image-text foundation models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}

@inproceedings{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9650--9660},
  year={2021}
}

@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}

@article{wang2023neural,
  title={Neural codec language models are zero-shot text to speech synthesizers},
  author={Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others},
  journal={arXiv preprint arXiv:2301.02111},
  year={2023}
}

@inproceedings{bizer2008linked,
  title={Linked data on the web (LDOW2008)},
  author={Bizer, Christian and Heath, Tom and Idehen, Kingsley and Berners-Lee, Tim},
  booktitle={Proceedings of the 17th international conference on World Wide Web},
  pages={1265--1266},
  year={2008}
}

@article{collobert2011natural,
  title={Natural language processing (almost) from scratch},
  author={Collobert, Ronan and Weston, Jason and Bottou, L{\'e}on and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
  journal={Journal of machine learning research},
  volume={12},
  number={ARTICLE},
  pages={2493--2537},
  year={2011}
}

@article{nasar2021named,
  title={Named entity recognition and relation extraction: State-of-the-art},
  author={Nasar, Zara and Jaffry, Syed Waqar and Malik, Muhammad Kamran},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={1},
  pages={1--39},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{wielinga1992kads,
  title={KADS: A modelling approach to knowledge engineering},
  author={Wielinga, Bob J and Schreiber, A Th and Breuker, Jost A},
  journal={Knowledge acquisition},
  volume={4},
  number={1},
  pages={5--53},
  year={1992},
  publisher={Elsevier}
}

@book{hayes1983building,
  title={Building expert systems},
  author={Hayes-Roth, Frederick and Waterman, Donald A and Lenat, Douglas B},
  year={1983},
  publisher={Addison-Wesley Longman Publishing Co., Inc.}
}

@misc{sourati2023casebased,
      title={Case-Based Reasoning with Language Models for Classification of Logical Fallacies}, 
      author={Zhivar Sourati and Filip Ilievski and Hông-Ân Sandlin and Alain Mermoud},
      year={2023},
      eprint={2301.11879},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{zhang2023using,
      title={Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata}, 
      author={Bohui Zhang and Ioannis Reklos and Nitisha Jain and Albert Meroño Peñuela and Elena Simperl},
      year={2023},
      eprint={2309.08491},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{arawjo2023chainforge,
      title={ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing}, 
      author={Ian Arawjo and Chelse Swoopes and Priyan Vaithilingam and Martin Wattenberg and Elena Glassman},
      year={2023},
      eprint={2309.09128},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}

@inproceedings{leake2021supporting,
      title={Supporting Case-Based Reasoning with Neural Networks: An Illustration for Case Adaptation},
      author={Leake, David and Ye, Xiaomeng and Crandall, David},
      booktitle={AAAI Spring Symposium: Combining Machine Learning with Knowledge Engineering},
      volume={2},
      year={2021}
}
